{
  "hash": "c0de169b056035cfb968b79b57146c37",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Analisi dei dati per la psicologia\"\nsubtitle: \"Appunti utili\"\nauthor: \"Antonio Di Mauro\"\ninclude-in-header: assets/header.html\nformat:\n  html:\n    theme: cosmo\n    code-fold: false\n    self-contained: true\n    toc: true   \n    toc-depth: 3 \n    toc-expand: 3\n    message: false\n    css: \"assets/custom.css\"\nexecute:\n  echo: false\n  warning: false\n  message: false\neditor: visual\n---\n\n\n\n## Indici di Statistica Inferenziale\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Tabella degli indici statistici inferenziali\n\n|Nome         |Simbolo   |Formula                                                    |Descrizione                                  |Interpretazione                              |Utilizzo                     |\n|:------------|:---------|:----------------------------------------------------------|:--------------------------------------------|:--------------------------------------------|:----------------------------|\n|Eta quadrato |$\\eta^2$  |$\\frac{SS_{\\text{effetto}}}{SS_{\\text{totale}}}$           |Quota di varianza spiegata da un effetto     |0.01 = piccolo, 0.06 = medio, 0.14+ = grande |ANOVA, ANCOVA                |\n|R quadrato   |$R^2$     |$1 - \\frac{SS_{\\text{residuo}}}{SS_{\\text{totale}}}$       |Varianza spiegata dal modello                |0–1; più alto è meglio                       |Regressione lineare          |\n|Correlazione |$r$       |$\\frac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y}$                |Relazione lineare tra due variabili          |-1 a +1                                      |Analisi bivariata            |\n|Cohen's d    |$d$       |$\\frac{\\bar{x}_1 - \\bar{x}_2}{s_p}$                        |Differenza standardizzata tra due medie      |0.2 = piccolo, 0.5 = medio, 0.8+ = grande    |Test t, esperimenti          |\n|Test t       |$t$       |$\\frac{\\bar{x}_1 - \\bar{x}_2}{SE}$                         |Confronto tra due medie                      |Valori alti → significativi                  |Inferenza su medie           |\n|Test F       |$F$       |$\\frac{MS_{\\text{modello}}}{MS_{\\text{errore}}}$           |Confronta varianze spiegate vs. non spiegate |>1 e p < .05 → effetto significativo         |ANOVA, regressione           |\n|AIC          |AIC       |$2k - 2\\ln(L)$                                             |Bilancia adattamento e complessità           |Più basso = migliore                         |Scelta tra modelli           |\n|BIC          |BIC       |$\\ln(n)k - 2\\ln(L)$                                        |Come AIC ma più penalizzante                 |Più basso = preferito                        |Modelli complessi            |\n|LOO-CV       |LOO       |Media log-verosimiglianze lasciando fuori 1 osservazione   |Validazione predittiva modello               |Più alto = migliore                          |Bayes, modelli predittivi    |\n|Z-score      |$z$       |$\\frac{x - \\mu}{\\sigma}$                                   |Distanza standardizzata da media             |&#124;z&#124; > 1.96 → significativo         |Standardizzazione, normalità |\n|p-value      |$p$       |-                                                          |Probabilità di osservare un dato sotto $H_0$ |p < 0.05 → significativo                     |Ogni test d'ipotesi          |\n|Alpha        |$\\alpha$  |-                                                          |Soglia di significatività                    |Tipicamente 0.05                             |Decisione inferenziale       |\n|Bayes Factor |$BF_{10}$ |$\\frac{P(D \\mid M_1)}{P(D \\mid M_0)}$                      |Supporto relativo per $H_1$ contro $H_0$     |>1 = favorevole a $H_1$                      |Statistica bayesiana         |\n|Deviance     |-         |$-2(\\log L_{\\text{modello}} - \\log L_{\\text{saturo}})$     |Misura bontà del fit nei GLM                 |Più basso = meglio                           |GLM, logistica, Poisson      |\n|WAIC         |WAIC      |Somma penalizzata di log-verosimiglianze                   |Criterio bayesiano di selezione modelli      |Più basso = migliore                         |Bayes                        |\n|ICC          |ICC       |$\\frac{\\sigma^2_{tra}}{\\sigma^2_{tra} + \\sigma^2_{intra}}$ |Affidabilità intra-classe                    |0–1; alto = coerente                         |Psicometria, modelli misti   |\n\n\n:::\n:::\n\n\n\n## Distribuzione Normale\n\n\n\n::: {.cell warnings='false'}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Proprietà della normale\n\n|Proprietà                  |Dettaglio                                                             |\n|:--------------------------|:---------------------------------------------------------------------|\n|Simmetria                  |Simmetrica rispetto alla media $\\mu$                                  |\n|Unimodale                  |Ha un solo picco (moda = media = mediana)                             |\n|Asintotica                 |Le code si avvicinano all'asse x ma non lo toccano mai                |\n|Area totale sotto la curva |1                                                                     |\n|Percentili importanti      |68% dei dati entro 1σ, 95% entro 2σ, 99.7% entro 3σ (regola empirica) |\n\n\n:::\n:::\n\n\n\n## Distribuzione t di Student\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Proprietà della t di Student\n\n|Proprietà             |Dettaglio                                                               |\n|:---------------------|:-----------------------------------------------------------------------|\n|Simmetrica            |È centrata su 0, come la normale                                        |\n|Code più pesanti      |Maggiore probabilità di valori estremi rispetto alla normale            |\n|Dipende da $df = n-1$ |$df=n−1$\tGradi di libertà, variano con la dimensione del campione        |\n|Converge alla normale |Per $( n \\to \\infty )$, la distribuzione t diventa una normale standard |\n|Varianza              |non definita per $df \\leq 2$                                            |\n\n\n:::\n:::\n\n\n\n## Distribuzione F di Fisher\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Proprietà della F di Fisher\n\n|Proprietà           |Dettaglio                                                           |\n|:-------------------|:-------------------------------------------------------------------|\n|Dominio             |Solo valori positivi: $F ∈ [0, +∞)$                                 |\n|Asimmetrica         |Ha una coda destra lunga, soprattutto per piccoli d.f.              |\n|Dipende da due d.f. |Numeratore $d_1$, denominatore $d_2$                                |\n|Media               |$\\frac{d_2} {d_2 - 2}$, se $d_2 > 2$                                |\n|Moda                |$\\frac {(d_1 - 2) d_2}{d_1 (d_2 + 2)}$, se $d_1 > 2$                |\n|Varianza            |Formula complessa; esiste solo per $d_2 > 4$                        |\n|Non simmetrica      |Spostata a destra; con d.f. grandi tende alla distribuzione normale |\n\n\n:::\n:::\n\n\n\n## Distribuzione Chi-quadrato\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\nTable: Proprietà della Chisq\n\n|Proprietà         |Dettaglio                                                                             |\n|:-----------------|:-------------------------------------------------------------------------------------|\n|Dominio           |Solo valori positivi: $\\chi^2 \\in [0, +\\infty)$                                       |\n|Asimmetrica       |Distribuzione asimmetrica a destra, più simmetrica all'aumentare dei gradi di libertà |\n|Dipende da d.f.   |Unico parametro: gradi di libertà $k$                                                 |\n|Media             |$\\mu = k$                                                                             |\n|Varianza          |$\\sigma^2 = 2k$                                                                       |\n|Moda              |$k - 2$, se $k \\geq 2$                                                                |\n|Simmetria         |Per $k > 30$ tende alla normale: $\\mathcal{N}(k, 2k)$                                 |\n|Somma di quadrati |$\\chi^2 = \\sum_{i=1}^{k} Z_i^2$, con $Z_i \\sim \\mathcal{N}(0, 1)$                     |\n\n\n:::\n:::\n\n\n\n## Assunti del modello di regressione\n\nCome tutti i modelli statistici, anche quello di regressione lineare si basa su una serie di assunti che devono essere rispettati ovvero:\n\n-   **Indipendenza dei predittori dall’errore.** Le X sono misurate senza errore. Tale assunto è evidente nei disegni sperimentali in cui i valori dei predittori sono sotto il diretto controllo dello sperimentatore. Nel resto dei casi i valori delle X sono ottenuti come risultato di un campionamento, pertanto questa assunzione implica che i predittori e gli errori siano indipendenti nella popolazione da cui vengono estratti.\n\n-   **Indipendenza delle osservazioni.** Tutte le coppie di errori $\\varepsilon i$ ed $\\varepsilon j$ sono tra loro indipendenti per ogni $i = j$. Detto in altri termini significa semplicemente che le osservazioni sono state campionate in modo indipendente l’una dall’altra.\n\n-   **Linearità.** Il valore atteso dell’errore per un dato valore di X2 è zero: $E(\\varepsilon i) = E(\\varepsilon|xi) = 0$. In pratica significa che il valore atteso della variabile dipendente, $E(Y)$, è una funzione lineare del predittore.\n\n-   **Normalità.** Gli errori sono distribuiti normalmente: $\\varepsilon i ∼ N(0,σ2)$. Questo implica che anche la distribuzione di yi sia normale con media pari a $\\beta0 + \\beta xi$.\n\n-   **Varianza costante.** La varianza degli errori è costante per qualunque valore di X : $V(\\varepsilon|xi) = σ2$. Anche in questo caso la varianza costante negli errori implica valori costanti anche della variabile Y per ciascun valore dato di X.\n\n## Interpretazione test parametrici\n\n| **Test** | **Tipo di Dato** | **Assunti** | **Verifica Assunti** | **Interpretazione (p-value)** |\n|---------------|---------------|---------------|---------------|---------------|\n| t-test indipendenti | Continua | Normalità, omogeneità varianze, indipendenza | Shapiro-Wilk, Levene | p \\< 0.05: differenza tra gruppi |\n| t-test appaiati | Continua (paired) | Normalità delle differenze | Shapiro-Wilk su differenze | p \\< 0.05: differenza tra condizioni |\n| ANOVA a una via | Continua + gruppi | Normalità, omogeneità varianze, indipendenza | Shapiro-Wilk, Levene, Bartlett | p \\< 0.05: almeno un gruppo differente |\n| ANOVA a due vie | Continua + 2 fattori | Come sopra + assenza di interazioni spurie | Verifica grafica, Levene, Bartlett | p \\< 0.05: effetti principali/interazione significativi |\n| MANOVA | Continua multivariata | Multinormalità, omogeneità covarianze, assenza multicollinearità | Box’s M, grafici, Bartlett | p \\< 0.05: almeno una differenza multivariata tra i gruppi |\n| Regressione lineare semplice | Continua | Linearità, normalità residui, omoscedasticità, indipendenza residui | Q-Q plot, Breusch-Pagan, Durbin-Watson, scatter plot | p \\< 0.05: predittore significativo |\n| Regressione multipla | Continua | Idem sopra + no multicollinearità | VIF, Condition Index | p \\< 0.05: almeno un predittore è significativo |\n| Test F per varianze | Continua | Normalità, indipendenza | Shapiro-Wilk, disegno | p \\< 0.05: varianze significativamente diverse |\n| Z-test | Continua, n \\> 30 | Conoscenza σ pop, normalità (o n grande) | Controllo teorico | p \\< 0.05: differenza tra media campione e popolazione |\n\n## Interpretazione test NON parametrici\n\n| **Test** | **Tipo di Dato** | **Assunti** | **Verifica Assunti** | **Interpretazione (p-value)** |\n|---------------|---------------|---------------|---------------|---------------|\n| Mann-Whitney U | Ordinale o continua non normale | Forma simile distribuzioni, indipendenza | Boxplot, istogrammi | p \\< 0.05: distribuzioni significativamente diverse |\n| Wilcoxon signed-rank | Paired non normali | Simmetria differenze, osservazioni appaiate | Boxplot delle differenze | p \\< 0.05: differenza significativa tra condizioni |\n| Kruskal-Wallis | Ordinale / continua | Forma simile, indipendenza | Istogrammi, boxplot | p \\< 0.05: almeno un gruppo differente |\n| Friedman test | Misure ripetute ordinali | Osservazioni appaiate | Disegno sperimentale | p \\< 0.05: almeno una condizione differente |\n| Spearman’s rho | Ordinale o continua | Relazione monotona, indipendenza | Scatterplot, test monotonia | p \\< 0.05: correlazione significativa |\n| Kendall’s tau | Ordinale, piccoli campioni | Relazione monotona, indipendenza | Scatterplot, test monotonia | p \\< 0.05: correlazione significativa |\n| Chi-quadro (indipendenza) | Categoriale | Frequenze attese ≥ 5, indipendenza | Tabella contingenza, conteggi | p \\< 0.05: associazione significativa |\n| Test esatto di Fisher | Categoriale, n piccolo | Frequenze molto basse, 2x2 | Tabella contingenza | p \\< 0.05: associazione significativa |\n| McNemar | Categoriale paired | Osservazioni appaiate | Tabella 2x2, differenze discordanti | p \\< 0.05: cambiamento significativo pre/post |\n\n## Interpretazione test per assunti\n\n| **Test** | **Assunto** | **Uso** | **Interpretazione (p-value)** |\n|------------------|------------------|------------------|------------------|\n| Shapiro-Wilk / Kolmogorov | Normalità | Normalità delle variabili o residui | p \\< 0.05: dati NON normali |\n| Levene / Bartlett | Omogeneità varianze | Test ANOVA, t-test indipendenti | p \\< 0.05: varianze NON omogenee |\n| Mauchly | Sfericità | Misure ripetute | p \\< 0.05: sfericità VIOLATA |\n| Breusch-Pagan / White | Omoscedasticità residui | Regressione | p \\< 0.05: eteroscedasticità presente |\n| Durbin-Watson | Indipendenza residui | Serie temporali / regressione | ≠ 2: autocorrelazione presente |\n| VIF / Tolerance | Multicollinearità | Regressione multipla | VIF \\> 10: multicollinearità problematicamente alta |\n\n## Schema decisionale: tipo di effetti casuali vs grafico atteso\n\n🔹 Formula del modello: `y ~ x + ( ? | gruppo )`\n\n| Specifica nella formula | Intercette variabili? | Pendenze variabili? | Tipo di grafico |\n|------------------|------------------|------------------|------------------|\n| `(1 | gruppo)` | ✅ Sì | ❌ No | **Intercette variabili** |\n| `(0 + x | gruppo)` | ❌ No | ✅ Sì | **Solo pendenze variabili (senza shift)** |\n| `(1 + x | gruppo)` | ✅ Sì | ✅ Sì | **Intercette e pendenze variabili** |\n| `(1 | gruppo) + (0 + x | gruppo)` | ✅ Sì | ✅ Sì | **Intercette e pendenze variabili (specificati separatamente)** |\n| `(x | gruppo)` | ✅ Sì | ✅ Sì | ✔️ Sintassi abbreviata per `(1 + x | gruppo)` |\n\n**Nota bene**\n\n-   Se **pendenze variabili** sono presenti → le linee nei grafici hanno **inclinazioni diverse** per ciascun gruppo.\n-   Se **solo intercette variano** → tutte le linee hanno **stessa inclinazione**, ma partono da **livelli diversi**.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n## Lettura output\n\n### Matrice PSI (Ψ) - effetti casuali\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n            (Intercept)        x1        x2\n(Intercept)   1.0827463 0.4994241 0.1954923\nx1            0.4994241 0.5254159 0.4191255\nx2            0.1954923 0.4191255 1.0667662\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n-   🔍 Interpreta la matrice\n\n**Diagonale** (verso sinistra) - varianze (quanto variano gli effetti casuali per intercetta, x1, x2)\n\n**Fuori diagonale** - covarianze (come variano insieme gli effetti nei gruppi)\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Regressione lineare\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = weight ~ height, data = dati)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.5830 -3.0758 -0.3937  2.6129 14.8068 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -21.7935     8.2313  -2.648  0.00945 ** \nheight        0.9634     0.0481  20.031  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.368 on 98 degrees of freedom\nMultiple R-squared:  0.8037,\tAdjusted R-squared:  0.8017 \nF-statistic: 401.2 on 1 and 98 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n-   **Call**: Specifica la formula usata: `weight ~ height`.\n-   **Residui**: Differenze tra i valori osservati e quelli stimati. Distribuiti idealmente attorno a 0.\n-   **Coefficienti**:\n    -   *Intercept*: valore teorico del peso quando l’altezza è zero (non realistico, ma serve al modello).\n    -   *Height*: effetto medio dell’altezza sul peso (es. +0.987 kg per ogni cm in più).\n-   **Errore standard residuo**: misura la dispersione dei residui. Più basso = stime più precise.\n-   **R² / Adjusted R²**: percentuale di variabilità spiegata dal modello (con e senza correzione).\n-   **F-statistic**: test globale di significatività del modello. Se p-value è basso → modello significativo.\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Regressione lineare - effetti fissi/random\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: mpg ~ hp + (1 + hp | cyl)\n   Data: mtcars\n\nREML criterion at convergence: 170.9\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.65419 -0.63457 -0.03825  0.48872  2.15522 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n cyl      (Intercept) 27.571143 5.25082       \n          hp           0.000613 0.02476  -1.00\n Residual              9.401205 3.06614       \nNumber of obs: 32, groups:  cyl, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 26.63970    3.39879   7.838\nhp          -0.05354    0.01680  -3.186\n\nCorrelation of Fixed Effects:\n   (Intr)\nhp -0.975\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n### 🔹 Effetti fissi (Fixed effects)\n\n-   **(Intercept)**: `30.74`\\\n    Questo valore rappresenta la stima del consumo medio di carburante (*mpg*) quando i cavalli (*hp*) sono pari a 0. Naturalmente, non è realistico avere 0 cavalli, ma questo valore serve come punto di riferimento nel modello.\n\n-   **hp**: `-0.068`\\\n    In media, all’aumentare di 1 unità nei cavalli (*hp*), ci si aspetta una **diminuzione di 0.068 miglia per gallone** nel consumo (*mpg*), tenendo conto delle variazioni tra gruppi (`cyl`).\n\n------------------------------------------------------------------------\n\n### 🔹 Effetti casuali (Random effects)\n\n-   Il termine `(1 + hp | cyl)` specifica che sia l’intercetta che il coefficiente di *hp* variano tra i gruppi definiti da **numero di cilindri (`cyl`)**.\n\n-   **Varianza dell'intercetta**:\\\n    Indica che esiste **una forte variabilità nel livello medio di *mpg* tra i gruppi di cilindrata**.\n\n-   **Varianza della pendenza di `hp`**:\\\n    Significa che l'effetto di *hp* su *mpg* **cambia leggermente tra i gruppi**, ma la variabilità è più contenuta rispetto all'intercetta.\n\n-   **Correlazione intercetta-pendenza**:\\\n    Gruppi con valori medi più alti di *mpg* tendono anche ad avere pendenze più \"piatte\" (meno negative), suggerendo una relazione positiva tra intercetta e pendenza.\n\n------------------------------------------------------------------------\n\n### 🔹 Errore residuo (Residual variance)\n\n-   **Varianza residua**:\\\n    Rappresenta la variabilità nei valori di *mpg* **non spiegata né dagli effetti fissi né da quelli casuali**. Questo è l’errore “interno” al gruppo.\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Analisi della varianza\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n            Df Sum Sq Mean Sq F value   Pr(>F)    \ngroup        2   1720   860.3   31.37 5.53e-11 ***\nResiduals   87   2386    27.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n-   **Obiettivo**: verificare se almeno un gruppo ha una media significativamente diversa.\n-   **Formula**: `values ~ group` confronta le medie dei gruppi A, B e C.\n-   **Gradi di libertà (DF)**:\n    -   *Tra gruppi*: `k - 1` → 3 − 1 = 2\n    -   *Entro gruppi (residuali)*: `n - k` → 90 − 3 = 87\n-   **Somma dei quadrati (Sum Sq)**:\n    -   *Between Groups*: variabilità spiegata dalle differenze tra le medie\n    -   *Residuals*: variabilità interna ai gruppi\n-   **Media dei quadrati (Mean Sq)**: Sum Sq / DF\n-   **F-value**: rapporto tra varianza spiegata e residua\n-   **Pr(\\>F)**:\n    -   Se \\< 0.05 → almeno un gruppo ha media significativamente diversa\n    -   Se \\> 0.05 → nessuna differenza significativa\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Confronto tra modelli (AIC)\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nGlobal model call: lm(formula = mpg ~ wt + hp + qsec + drat, data = mtcars)\n---\nModel selection table \n   (Intrc)  drat       hp    qsec     wt df   logLik   AIC delta weight\n11  37.230       -0.03177         -3.878  4  -74.326 156.7  0.00  0.181\n14  11.390 1.656           0.9462 -4.398  5  -73.352 156.7  0.05  0.176\n13  19.750                 0.9292 -5.048  4  -74.360 156.7  0.07  0.175\n12  29.390 1.615 -0.03223         -3.228  5  -73.366 156.7  0.08  0.174\n16  19.260 1.657 -0.01784  0.5275 -3.708  6  -72.509 157.0  0.36  0.151\n15  27.610       -0.01782  0.5108 -4.359  5  -73.571 157.1  0.49  0.141\n9   37.290                        -5.344  3  -80.015 166.0  9.38  0.002\n10  30.290 1.442                  -4.783  4  -79.484 167.0 10.32  0.001\n4   10.790 4.698 -0.05179                 4  -80.752 169.5 12.85  0.000\n8   17.740 4.429 -0.05797 -0.2841         5  -80.561 171.1 14.47  0.000\n7   48.320       -0.08459 -0.8866         4  -86.170 180.3 23.69  0.000\n3   30.100       -0.06823                 3  -87.619 181.2 24.59  0.000\n6  -27.840 7.309           1.2130         4  -88.026 184.1 27.40  0.000\n2   -7.525 7.678                          3  -92.400 190.8 34.15  0.000\n5   -5.114                 1.4120         3  -99.294 204.6 47.94  0.000\n1   20.090                                2 -102.378 208.8 52.10  0.000\nModels ranked by AIC(x) \n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n-   **Obiettivo**: confrontare tutti i sottoinsiemi possibili del modello globale per identificare il modello più parsimonioso secondo il criterio AIC.\n-   **Colonne principali**:\n    -   `Int`, `wt`, `hp`, `qsec`, `drat`: indicano la presenza (`+`) o assenza di ciascun termine nel modello.\n    -   `df`: numero di parametri stimati nel modello.\n    -   `logLik`: log-likelihood del modello.\n    -   `AIC`: criterio di informazione di Akaike; valori più bassi indicano modelli migliori.\n    -   `delta`: differenza tra l'AIC del modello corrente e il minimo AIC tra tutti i modelli.\n    -   `weight`: peso di Akaike, rappresenta la probabilità relativa che il modello sia il migliore tra quelli considerati.\n-   **Interpretazione dei risultati**:\n    -   Il modello con `delta = 0` è il migliore secondo l'AIC.\n    -   Modelli con `delta < 2` hanno un supporto sostanziale e possono essere considerati competitivi.\n    -   I pesi di Akaike (`weight`) possono essere utilizzati per il model averaging o per valutare l'evidenza relativa a favore di ciascun modello.\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Confronto tra modelli (LOO)\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n              model    looic se_looic  elpd_diff   se_diff\nmod2       mod1: x1 388.6006 12.73663  0.0000000 0.0000000\nmod3    mod2: x1+x2 378.9653 13.38565 -0.9298536 0.5735233\nmod1 mod3: x1+x2+x3 380.8250 13.39839 -4.8176874 3.4359110\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n**Significato degli indici riportati:**\n\n-   `looic` (**Leave-One-Out Information Criterion**): misura la bontà predittiva del modello. Valori **più bassi** indicano **migliore performance predittiva**.\n-   `se_looic`: è l’**errore standard** associato a `looic`. Indica l’incertezza nella stima di `looic`.\n-   `elpd_diff` (**expected log predictive density difference**): differenza della capacità predittiva di ciascun modello rispetto al **migliore** (quello con `elpd_diff = 0`). Valori **negativi** indicano prestazioni inferiori.\n-   `se_diff`: errore standard associato a `elpd_diff`. Serve per valutare la **significatività** della differenza: se `elpd_diff` è maggiore di **2×se_diff**, la differenza è considerata sostanziale.\n\n------------------------------------------------------------------------\n\n**Risultati nel confronto tra modelli:**\n\n-   Il modello **mod2: x1 + x2** ha il valore di **looic più basso**, quindi è il **miglior modello predittivo** tra quelli considerati.\n-   Il modello **mod1: x1** ha `elpd_diff = -12.2` e `se_diff = 4.3`, quindi è **significativamente peggiore** di mod2 (la differenza supera 2 volte l'errore standard).\n-   Il modello **mod3: x1 + x2 + x3** ha `elpd_diff = -0.8` e `se_diff = 0.9`, una differenza **non significativa** rispetto a mod2. Aggiungere la variabile `x3` **non migliora** in modo rilevante la predizione.\n\nIn sintesi, **mod2 è il miglior compromesso tra semplicità e accuratezza predittiva**.\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Chisq Test per modelli annidati\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nData: sleepstudy\nModels:\nm1: Reaction ~ 1 + (1 | Subject)\nm2: Reaction ~ Days + (1 | Subject)\nm3: Reaction ~ Days + I(Days^2) + (1 | Subject)\nm4: Reaction ~ Days + I(Days^2) + I(Days^3) + (1 | Subject)\nm5: Reaction ~ Days + I(Days^2) + I(Days^3) + I(Days^4) + (1 | Subject)\n   npar    AIC    BIC  logLik deviance    Chisq Df Pr(>Chisq)    \nm1    3 1916.5 1926.1 -955.27   1910.5                           \nm2    4 1802.1 1814.8 -897.04   1794.1 116.4624  1     <2e-16 ***\nm3    5 1802.9 1818.9 -896.47   1792.9   1.1349  1     0.2867    \nm4    6 1804.9 1824.1 -896.47   1792.9   0.0094  1     0.9226    \nm5    7 1806.3 1828.6 -896.14   1792.3   0.6599  1     0.4166    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n-   Sono stati confrontati 5 modelli misti annidati:\n    -   Tutti includono un termine casuale per il soggetto (`(1 | Subject)`).\n    -   Ogni modello aggiunge progressivamente effetti fissi: `Days`, `Days^2`, ecc.\n-   La tabella mostra:\n    -   **AIC, BIC**: criteri di bontà del modello; valori più bassi sono migliori.\n    -   **logLik**: log-verosimiglianza del modello.\n    -   **Chisq**: statistica del test del rapporto di verosimiglianza (LRT).\n    -   **Df diff**: differenza nei gradi di libertà tra i modelli.\n    -   **Pr(\\>Chisq)**: p-value del test LRT.\n-   Se il p-value \\< 0.05 → l’aggiunta della nuova variabile migliora significativamente il modello.\n-   È importante usare `REML = FALSE` per confronti validi tra modelli con effetti fissi diversi.\n-   L’ultimo modello con miglioramento significativo e AIC basso può essere selezionato come finale.\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n### Studio di potenza\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Two Sample Cohen's d \n\n      data.name = Ym and Yf\n      statistic = 0.8856\n         effect = large\n```\n\n\n:::\n:::\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n- **Statistic:** `d = 0.8856`\n- **Interpretazione:** **Effetto grande** secondo le soglie di Cohen:\n\n  - piccolo: `~ 0.2`\n  - medio: `~ 0.5`\n  - grande: `~ 0.8`\n\n💡 Questo significa che la **differenza media tra i gruppi `Ym` e `Yf`** è ampia rispetto alla variabilità complessiva.  \nL'effetto è **sufficientemente forte da essere considerato rilevante**\n\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Errori di tipo M o S \n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tDesign Analysis\n\nHypothesized effect:  cohen_d = 0.4 \n\nStudy characteristics:\n   test_method   sample_n1   sample_n2   alternative   sig_level   df\n   two_sample    8           8           greater       0.05        14\n\nInferential risks:\n   power   typeM   typeS\n   0.182   2.887   0    \n\nCritical value(s): cohen_d  =  0.881\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n- **Potenza**: `0.182`  \n   Il test ha solo **il 18.2% di probabilità** di rilevare un effetto vero di `d = 0.4` se esiste.  \n  Questo valore è **molto inferiore al livello desiderato di 0.80**, indicando un **alto rischio di falso negativo (errore di tipo II)**.\n\n- **Errore di tipo M (Magnitude)**: `2.887`  \n   Se ottieni un risultato significativo, è probabile che l'effetto stimato sarà **quasi 3 volte più grande** di quello reale.  \n  Questo riflette un **rischio molto elevato di sovrastimare l’effetto** in caso di significatività.\n\n- **Errore di tipo S (Sign)**: `0`  \n   Il rischio che l’effetto significativo abbia **segno opposto** rispetto a quello reale è nullo.  \n  Questo è possibile perché il test è **unilaterale** (\"greater\"), quindi non considera effetti nel verso opposto.\n\n- **Valore critico di d**: `0.881`  \n   Perché il risultato sia significativo a `p < 0.05`, l'effetto osservato dovrà essere **≥ 0.881**.  \n  Questo è **più del doppio dell'effetto ipotizzato**, il che rende difficile ottenere significatività con questo disegno.\n\n📌 **Conclusione**:  \nIl disegno attuale (n = 8 per gruppo) è **sottodimensionato** per rilevare un effetto di `d = 0.4` con adeguata potenza.  \nSono raccomandati **campioni più grandi** per ridurre il rischio di errore tipo M e aumentare la potenza.\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Bayes Factor Analysis\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\nBayes factor analysis\n--------------\n[1] wt + hp : 17.27075 ±0.01%\n\nAgainst denominator:\n  mpg ~ wt \n---\nBayes factor type: BFlinearModel, JZS\n```\n\n\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n-   Sono stati confrontati due modelli:\n    -   **BF1**: mpg \\~ wt\n    -   **BF2**: mpg \\~ wt + hp\n-   Il **Bayes Factor (BF)** confronta direttamente la probabilità dei dati sotto i due modelli.\n-   Valore calcolato: `BF2 / BF1`\n    -   Se **BF \\> 1** → i dati supportano di più il secondo modello.\n    -   Se **BF \\< 1** → i dati supportano di più il primo modello.\n-   **Interpretazione standard del BF**:\n    -   1–3: evidenza debole\n    -   3–10: evidenza moderata\n    -   (\\>10): evidenza forte a favore del modello al numeratore\n-   Il BF è una misura continua della forza di evidenza, a differenza del p-value che si basa su soglie arbitrarie.\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Log Relative Evidence tra modelli (Bayes Factor)\n\n\n\n```{=html}\n<style>\n.flex-container {\n  display: flex;\n  flex-wrap: wrap;\n  gap: 2rem;\n  margin-left: -2rem;\n  margin-right: -2rem;\n}\n\n.flex-item {\n  flex: 1 1 48%;\n  min-width: 300px;\n}\n\n.card {\n  background-color: #f9f9f9;\n  padding: 1rem;\n  border-radius: 12px;\n  box-shadow: 0 2px 6px rgba(0,0,0,0.05);\n}\n</style>\n\n<div class=\"flex-container\">\n  <div class=\"flex-item card\">\n```\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n\n::: {.callout-note collapse=\"true\" title=\"Mostra interpretazione dettagliata\"}\n## 🧾 Interpretazione dell'Output\n\n-   Ogni cella della heatmap rappresenta il **logaritmo del Bayes Factor** tra due modelli specifici.\n-   Il colore indica la forza dell'evidenza:\n    -   **Rosso**: evidenza a favore del modello sulla riga rispetto a quello sulla colonna.\n    -   **Blu**: evidenza a favore del modello sulla colonna rispetto a quello sulla riga.\n    -   **Bianco**: evidenza neutra o trascurabile.\n-   La scala dei colori è limitata tra -3 e 3 per facilitare l'interpretazione visiva.\n-   Questo tipo di visualizzazione consente un confronto diretto e intuitivo tra tutti i modelli considerati.\n:::\n\n\n\n```{=html}\n </div>\n</div>\n```\n\n\n\n### Interpretazione SEM - path Diagram\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Sito-github_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n::: {.callout-note title=\"Interpretazione e schema decisionale per il conteggio dei parametri in un modello SEM\"}\nIl diagramma SEM visualizzato rappresenta una struttura di relazioni tra **variabili latenti**, **variabili osservate**, e le **associazioni** tra di esse. È possibile utilizzare il diagramma per stimare il **numero totale di parametri** del modello sulla base della **tipologia e direzione delle frecce**, nonché della **presenza di varianze e covarianze**.\n\n### 📌 Categorie principali di parametri da contare\n\n1.  **Carichi fattoriali (Loadings)**\n    -   Frecce **direzionali** da fattori latenti → variabili osservate\\\n    -   Numero: 1 parametro per ciascuna freccia\n2.  **Regressioni strutturali (Path coefficients)**\n    -   Frecce **direzionali** tra variabili latenti o da manifesti a latenti\\\n    -   Numero: 1 parametro per ciascuna freccia\n3.  **Varianze**\n    -   Rappresentate da **semicerchi** che si collegano a una singola variabile\\\n    -   Ogni variabile latente e ogni variabile manifestata ha una **varianza stimata**\n    -   Numero: 1 parametro per variabile\n4.  **Covarianze**\n    -   Rappresentate da **frecce curve** tra due variabili senza direzione causale (↔)\\\n    -   Spesso tra variabili latenti o tra errori di misura\\\n    -   Numero: 1 parametro per ciascuna coppia correlata\n\n## Tipologie di variabili\n\n| Tipo di variabile | Caratteristiche | Esempi |\n|------------------------|------------------------|------------------------|\n| **Esogena** | Non è spiegata da altre variabili nel modello | Età, Sesso, Condizione sperimentale |\n| **Endogena** | È spiegata da almeno una variabile nel modello | Depressione, Stress, Prestazione |\n\n------------------------------------------------------------------------\n\n## Dal grafo SEM: come riconoscerle?\n\n-   **Freccia in entrata** (→) = variabile **endogena**\n-   **Solo frecce in uscita** = variabile **esogena**\n-   Le **variabili latenti** possono essere endogene o esogene a seconda del modello\n:::\n\n## R - online !\n\n::: custom-r-snippet\n\n\n```{=html}\n<textarea id=\"rcode\" placeholder='Es. print(\"Hello, world!\")'\n  style=\"width: 100%; height: 120px; font-family: monospace; font-size: 14px; margin-bottom: 10px;\"></textarea>\n```\n\n```{=html}\n<button onclick=\"loadCode()\" style=\"\n  padding: 8px 16px;\n  font-size: 14px;\n  background-color: #007acc;\n  color: white;\n  border: none;\n  border-radius: 4px;\n  cursor: pointer;\n  margin-bottom: 10px;\">\n```\n\n\n\nEsegui codice\n\n</button>\n\n<iframe id=\"rframe\" src=\"https://rdrr.io/snippets/embed/\" style=\"width: 100%; height: 400px; border: 1px solid #ccc;\">\n\n</iframe>\n\n\n\n```{=html}\n<script>\n  function loadCode() {\n    const code = document.getElementById(\"rcode\").value;\n    const encoded = encodeURIComponent(code);\n    const url = `https://rdrr.io/snippets/embed/?code=${encoded}`;\n    document.getElementById(\"rframe\").src = url;\n  }\n</script>\n```\n\n\n:::\n",
    "supporting": [
      "Sito-github_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}