[
  {
    "objectID": "R-online.html",
    "href": "R-online.html",
    "title": "Analisi dei dati per la psicologia",
    "section": "",
    "text": "Esegui codice"
  },
  {
    "objectID": "R-online.html#r---online",
    "href": "R-online.html#r---online",
    "title": "Analisi dei dati per la psicologia",
    "section": "",
    "text": "Esegui codice"
  },
  {
    "objectID": "Grafici.html",
    "href": "Grafici.html",
    "title": "Analisi dei dati per la psicologia",
    "section": "",
    "text": "Asse X (orizzontale): rappresenta gli intervalli dei valori della variabile (es. consumo, et√†, punteggi).\nAsse Y (verticale): mostra la frequenza (quante osservazioni cadono in ciascun intervallo).\n\n\n\n\n\nSimmetrica ‚Üí distribuzione equilibrata intorno alla media.\nAsimmetrica a destra ‚Üí pochi valori molto alti (coda lunga a destra).\nAsimmetrica a sinistra ‚Üí pochi valori molto bassi.\nA campana ‚Üí simile a una distribuzione normale.\nMultimodale ‚Üí pi√π picchi = possibili gruppi o sottocategorie.\n\n\n\n\n\nLa barra pi√π alta mostra l‚Äôintervallo pi√π frequente.\nTi d√† un‚Äôindicazione della tendenza centrale.\n\n\n\n\n\nBarre distribuite su intervalli ampi ‚Üí alta variabilit√† nei dati.\nBarre concentrate in uno stretto intervallo ‚Üí bassa variabilit√†.\n\n\n\n\n\nBarre isolate ‚Üí possibili valori anomali (outlier).\nCode lunghe ‚Üí valori estremi meno frequenti.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAspetto\nCosa guardare\nCosa indica\n\n\n\n\nAsse X\nIntervalli della variabile\nCosa stai misurando\n\n\nAsse Y\nAltezza delle barre\nFrequenza delle osservazioni\n\n\nBarra pi√π alta\nValore/modo pi√π frequente\nTendenza centrale\n\n\nForma simmetrica o no\nAsimmetria o code\nSquilibri, outlier\n\n\nLarghezza complessiva\nBase dell‚Äôistogramma\nVariazione/dispersione nei dati"
  },
  {
    "objectID": "Grafici.html#istogramma",
    "href": "Grafici.html#istogramma",
    "title": "Analisi dei dati per la psicologia",
    "section": "",
    "text": "Asse X (orizzontale): rappresenta gli intervalli dei valori della variabile (es. consumo, et√†, punteggi).\nAsse Y (verticale): mostra la frequenza (quante osservazioni cadono in ciascun intervallo).\n\n\n\n\n\nSimmetrica ‚Üí distribuzione equilibrata intorno alla media.\nAsimmetrica a destra ‚Üí pochi valori molto alti (coda lunga a destra).\nAsimmetrica a sinistra ‚Üí pochi valori molto bassi.\nA campana ‚Üí simile a una distribuzione normale.\nMultimodale ‚Üí pi√π picchi = possibili gruppi o sottocategorie.\n\n\n\n\n\nLa barra pi√π alta mostra l‚Äôintervallo pi√π frequente.\nTi d√† un‚Äôindicazione della tendenza centrale.\n\n\n\n\n\nBarre distribuite su intervalli ampi ‚Üí alta variabilit√† nei dati.\nBarre concentrate in uno stretto intervallo ‚Üí bassa variabilit√†.\n\n\n\n\n\nBarre isolate ‚Üí possibili valori anomali (outlier).\nCode lunghe ‚Üí valori estremi meno frequenti.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAspetto\nCosa guardare\nCosa indica\n\n\n\n\nAsse X\nIntervalli della variabile\nCosa stai misurando\n\n\nAsse Y\nAltezza delle barre\nFrequenza delle osservazioni\n\n\nBarra pi√π alta\nValore/modo pi√π frequente\nTendenza centrale\n\n\nForma simmetrica o no\nAsimmetria o code\nSquilibri, outlier\n\n\nLarghezza complessiva\nBase dell‚Äôistogramma\nVariazione/dispersione nei dati"
  },
  {
    "objectID": "Grafici.html#boxplot",
    "href": "Grafici.html#boxplot",
    "title": "Analisi dei dati per la psicologia",
    "section": "Boxplot",
    "text": "Boxplot\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nüì¶ Come si legge un boxplot? ‚Äì Guida schematica e utile\n\n\n‚úÖ 1. Comprendi gli elementi base\n\nLinea centrale nella scatola: √® la mediana (valore centrale).\nBordi della scatola (box): indicano il 1¬∞ quartile (Q1) e il 3¬∞ quartile (Q3) ‚Üí contengono il 50% centrale dei dati.\n‚ÄúWhiskers‚Äù (linee esterne): si estendono fino ai dati non considerati outlier, solitamente entro 1.5 √ó IQR.\nPunti isolati fuori dai whiskers: sono outlier (valori anomali).\n\n\n\n‚úÖ 2. Valuta la simmetria\n\nSe la mediana √® centrata nella scatola e i whisker sono di lunghezza simile ‚Üí distribuzione simmetrica.\nSe la mediana √® spostata o un whisker √® molto pi√π lungo ‚Üí asimmetria.\n\n\n\n‚úÖ 3. Analizza la dispersione\n\nLarghezza della scatola (Q3 - Q1) = Intervallo Interquartile (IQR) ‚Üí misura la variabilit√† centrale dei dati.\nWhisker lunghi ‚Üí valori pi√π dispersi.\nWhisker corti ‚Üí valori pi√π concentrati.\n\n\n\n‚úÖ 4. Individua gli outlier\n\nPunti fuori dai whiskers ‚Üí valori estremi.\nImportante valutarli nel contesto: errori? valori reali ma rari?\n\n\n\n\nüìå Riepilogo ‚Äì Schema utile\n\n\n\n\n\n\n\n\nElemento\nCosa rappresenta\nCosa ci dice\n\n\n\n\nLinea centrale\nMediana\nTendenza centrale\n\n\nBox (Q1 - Q3)\nIntervallo interquartile (IQR)\nVariabilit√† centrale\n\n\nWhiskers\nDati non-outlier\nDispersione esterna\n\n\nOutlier\nValori fuori da 1.5 √ó IQR\nValori estremi (da approfondire)\n\n\nSimmetria\nPosizione mediana e lunghezza whiskers\nForma della distribuzione (asimmetrie)"
  },
  {
    "objectID": "Grafici.html#violin-plot",
    "href": "Grafici.html#violin-plot",
    "title": "Analisi dei dati per la psicologia",
    "section": "Violin Plot",
    "text": "Violin Plot\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nüéª Come si legge un violin plot? ‚Äì Guida schematica e utile\n\n\n‚úÖ 1. Interpreta le componenti\n\nForma a ‚Äúviolino‚Äù: rappresenta la distribuzione dei dati tramite una curva di densit√† speculare.\nLarghezza in ciascun punto verticale: indica quanto sono frequenti i valori in quell‚Äôintervallo.\nLinea interna o box centrale (opzionale): include mediana e intervallo interquartile (IQR), come in un boxplot.\n\n\n\n‚úÖ 2. Valuta la densit√†\n\nLe zone pi√π larghe rappresentano concentrazioni di dati.\nLe zone pi√π strette indicano valori meno frequenti.\nA differenza del boxplot, la distribuzione non √® limitata a una forma rettangolare ‚Üí puoi vedere la forma reale della distribuzione.\n\n\n\n‚úÖ 3. Analizza la simmetria\n\nSe le due met√† del violino sono simmetriche ‚Üí distribuzione bilanciata.\nSe una met√† √® pi√π larga o pi√π lunga ‚Üí asimmetria.\n\n\n\n‚úÖ 4. Combina con il boxplot interno\n\nSe presente, il box centrale fornisce la mediana e il range interquartile.\nAiuta a confrontare forma e centro della distribuzione contemporaneamente.\n\n\n\n\nüìå Riepilogo ‚Äì Schema utile\n\n\n\n\n\n\n\n\nElemento\nCosa rappresenta\nCosa ci dice\n\n\n\n\nLarghezza del violino\nDensit√† di dati in ogni intervallo\nFrequenza relativa\n\n\nForma complessiva\nDistribuzione\nSimmetria, multimodalit√†\n\n\nBox centrale (se presente)\nMediana + IQR\nTendenza centrale e variabilit√†\n\n\nEstremit√† del violino\nCode della distribuzione\nValori estremi (non necessariamente outlier)\n\n\nAsimmetria visiva\nDifferenza tra le due met√†\nSquilibri nei dati"
  },
  {
    "objectID": "Grafici.html#qq-plot",
    "href": "Grafici.html#qq-plot",
    "title": "Analisi dei dati per la psicologia",
    "section": "QQ plot",
    "text": "QQ plot\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nüìà Come si legge un Q-Q plot? ‚Äì Guida schematica e utile\n\n\n‚úÖ 1. Cos‚Äô√® un Q-Q plot?\n\nUn Q-Q plot confronta i quantili di una variabile osservata con i quantili di una distribuzione teorica (di solito normale).\nServe per verificare se i dati seguono una certa distribuzione.\n\n\n\n‚úÖ 2. Leggi l‚Äôasse X e Y\n\nAsse X: quantili attesi (dalla distribuzione teorica).\nAsse Y: quantili osservati (dai tuoi dati).\n\n\n\n\n‚úÖ 3. Interpreta l‚Äôallineamento\n\nSe i punti stanno sulla linea diagonale (linea di riferimento) ‚Üí i dati seguono la distribuzione teorica (es. distribuzione normale).\nSe i punti deviano dalla linea ‚Üí i dati non seguono la distribuzione attesa.\n\n\n\n\n‚úÖ 4. Analizza le deviazioni\n\nDeviazione in alto o in basso alle estremit√† ‚Üí i dati hanno code pi√π pesanti o leggere rispetto alla distribuzione teorica.\nCurvatura a S o a gomito ‚Üí indica asimmetria o skewness:\n\nCurva a S (convessa-concava) ‚Üí coda lunga a destra (asimmetria positiva).\nCurva a gomito (concava-convessa) ‚Üí coda lunga a sinistra (asimmetria negativa).\n\n\n\n\n\nüìå Riepilogo ‚Äì Schema utile\n\n\n\n\n\n\n\n\nAspetto\nCosa osservare\nCosa indica\n\n\n\n\nAllineamento dei punti\nSegue la linea diagonale\nI dati seguono la distribuzione teorica\n\n\nDeviazione alle estremit√†\nCode pi√π o meno pesanti\nDifferenze nella coda\n\n\nCurvatura dei punti\nForma a S o a gomito\nAsimmetria (skewness)\n\n\nDistribuzione di confronto\nDi solito normale (ma pu√≤ variare)\nDeve essere nota per interpretare correttamente"
  },
  {
    "objectID": "Grafici.html#scatter-plot",
    "href": "Grafici.html#scatter-plot",
    "title": "Analisi dei dati per la psicologia",
    "section": "Scatter-plot",
    "text": "Scatter-plot\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nüîµ Come si legge uno scatterplot? ‚Äì Guida schematica e utile\n\n\n‚úÖ 1. Cosa mostra uno scatterplot?\n\nOgni punto rappresenta una coppia di valori per due variabili quantitative (X e Y).\nServe a visualizzare relazioni, tendenze e correlazioni tra due variabili.\n\n\n\n\n‚úÖ 2. Leggi gli assi\n\nAsse X (orizzontale): variabile indipendente (predictor).\nAsse Y (verticale): variabile dipendente (risposta).\n\n\n\n\n‚úÖ 3. Osserva la tendenza generale\n\nAndamento crescente (‚Üó): correlazione positiva ‚Üí all‚Äôaumentare di X, aumenta anche Y.\nAndamento decrescente (‚Üò): correlazione negativa ‚Üí all‚Äôaumentare di X, Y diminuisce.\nNessun andamento visibile: assenza di correlazione ‚Üí i dati sono sparsi casualmente.\n\n\n\n\n‚úÖ 4. Valuta la forza della relazione\n\nPunti vicini a una linea ideale ‚Üí relazione forte.\nPunti molto dispersi ‚Üí relazione debole.\nLa forza pu√≤ essere valutata visivamente o con il coefficiente di correlazione.\n\n\n\n\n‚úÖ 5. Cerca pattern o anomalie\n\nGruppi separati ‚Üí possibili sottogruppi (cluster).\nAndamenti curvi/non lineari ‚Üí possibile relazione non lineare.\nPunti lontani dalla nuvola ‚Üí outlier (valori anomali).\n\n\n\n\nüìå Riepilogo ‚Äì Schema utile\n\n\n\n\n\n\n\n\nAspetto\nCosa osservare\nCosa indica\n\n\n\n\nDistribuzione dei punti\nDensit√†, forma, direzione\nTipo di relazione (positiva, negativa, nulla)\n\n\nLinearit√†\nAllineamento lungo una retta\nRelazione lineare\n\n\nDispersione\nVicinanza dei punti\nForza della correlazione\n\n\nOutlier\nPunti isolati\nValori anomali da approfondire\n\n\nPattern insoliti\nCurve, gruppi, archi\nRelazioni non lineari o sottogruppi"
  },
  {
    "objectID": "Grafici.html#residual-plot",
    "href": "Grafici.html#residual-plot",
    "title": "Analisi dei dati per la psicologia",
    "section": "Residual plot",
    "text": "Residual plot\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n‚ôªÔ∏è Come si legge un residual plot? ‚Äì Guida schematica e utile\n\n\n‚úÖ 1. Cos‚Äô√® un residual plot?\n\nMostra i residui (errori) di un modello di regressione ‚Üí la differenza tra i valori osservati e quelli previsti.\nAsse X: valori predetti dal modello.\nAsse Y: residui (valori osservati ‚àí valori predetti).\n\n\n\n\n‚úÖ 2. Obiettivo principale\n\nVerificare se i presupposti della regressione sono soddisfatti:\n\nLinearit√†\nOmoscedasticit√† (varianza costante)\nAssenza di pattern sistematici\n\n\n\n\n\n‚úÖ 3. Cosa cercare\n\n\n\n\n\n\n\nPattern\nInterpretazione\n\n\n\n\nPunti distribuiti a caso\n‚úÖ Il modello √® adeguato (errori casuali, omoscedastici).\n\n\nForma a U o curva\n‚ùå Mancanza di linearit√† ‚Üí forse serve un modello non lineare.\n\n\nFunnel (apertura/chiusura)\n‚ùå Eteroschedasticit√† ‚Üí la varianza degli errori cambia.\n\n\nPunti molto distanti\n‚ùó Outlier nei residui ‚Üí possibili casi problematici.\n\n\n\n\n\n\n‚úÖ 4. Cosa idealmente si vuole vedere\n\nUna nuvola di punti distribuita in modo casuale attorno alla linea orizzontale y = 0.\nNessun pattern evidente ‚Üí i residui sono indipendenti e distribuiti normalmente con media zero.\n\n\n\n\nüìå Riepilogo ‚Äì Schema utile\n\n\n\n\n\n\n\n\nAspetto\nCosa osservare\nCosa indica\n\n\n\n\nDispersione casuale\nPunti sparsi intorno a y = 0\nBuon modello lineare\n\n\nPattern curvo o forma a U\nTrend sistematici nei residui\nRelazione non lineare\n\n\nFunnel (cono aperto/chiuso)\nVarianza non costante\nEteroschedasticit√†\n\n\nOutlier nei residui\nPunti molto distanti\nOsservazioni anomale o influenti"
  },
  {
    "objectID": "Grafici.html#boxplot-per-residui-gruppi",
    "href": "Grafici.html#boxplot-per-residui-gruppi",
    "title": "Analisi dei dati per la psicologia",
    "section": "Boxplot per residui gruppi",
    "text": "Boxplot per residui gruppi\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nüì¶üìä Come si leggono i boxplot dei residui per gruppi? ‚Äì Guida schematica e utile\n\n\n‚úÖ 1. Cosa mostrano questi boxplot?\n\nConfrontano la distribuzione dei residui tra diversi gruppi (es. trattamenti, categorie).\nOgni box rappresenta la variabilit√† degli errori del modello all‚Äôinterno di un gruppo.\n\n\n\n\n‚úÖ 2. Obiettivo principale\n\nValutare se il modello si comporta in modo coerente tra i gruppi:\n\nVarianza simile? ‚Üí ok\nMediana dei residui ‚âà 0? ‚Üí ok\nOutlier concentrati in certi gruppi? ‚Üí potenziale problema\n\n\n\n\n\n‚úÖ 3. Cosa osservare nei boxplot\n\n\n\n\n\n\n\nOsservazione\nInterpretazione\n\n\n\n\n‚úÖ Box simili in tutti i gruppi\nResidui distribuiti in modo coerente ‚Üí modello stabile\n\n\n‚úÖ Mediane vicine a 0\nIl modello non sovrastima n√© sottostima i gruppi\n\n\n‚ùå Box molto diversi tra gruppi\nEteroschedasticit√† ‚Üí varianza non costante\n\n\n‚ùå Mediane lontane da 0\nSistematici errori di stima per alcuni gruppi\n\n\n‚ùó Molti outlier in un gruppo\nDati problematici o mal modellati\n\n\n\n\n\n\n‚úÖ 4. Quando √® utile usarli?\n\nDopo aver adattato un modello lineare con variabili categoriali.\nPer controllare presupposti di omoscedasticit√† (es. ANOVA, regressione con fattori).\nPer rilevare bias o incoerenze tra gruppi.\n\n\n\n\nüìå Riepilogo ‚Äì Schema utile\n\n\n\n\n\n\n\n\nAspetto\nCosa osservare\nCosa indica\n\n\n\n\nVarianza dei box\nSimile tra gruppi\nOmogeneit√† delle varianze (buono)\n\n\nMediana\nVicina a 0 in ogni gruppo\nNessun bias sistematico\n\n\nOutlier\nConcentrati in pochi gruppi\nPossibili anomalie\n\n\nDifferenze forti nei box\nModello si adatta diversamente\nViolazione presupposti del modello"
  },
  {
    "objectID": "Grafici.html#diagnostica-dei-modelli",
    "href": "Grafici.html#diagnostica-dei-modelli",
    "title": "Analisi dei dati per la psicologia",
    "section": "Diagnostica dei modelli",
    "text": "Diagnostica dei modelli\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nüßæ Interpretazione dei grafici diagnostici ‚Äì check_model()\n\n\n‚úÖ 1. Residuals vs Fitted\n\nDistribuzione casuale attorno alla linea orizzontale indica:\n\nCorretta specificazione del modello\nVarianza costante (omoschedasticit√†)\n\nPattern (curve, funnel) ‚Üí possibile violazione di linearit√† o eteroschedasticit√†.\n\n\n\n\n‚úÖ 2. Q-Q Plot dei residui\n\nPunti allineati alla diagonale ‚Üí i residui seguono una distribuzione normale.\nDeviazioni marcate alle estremit√† ‚Üí possibili problemi di normalit√† (code pesanti o leggere).\n\n\n\n\n‚úÖ 3. Scale-Location (Spread vs Fitted)\n\nVerifica la costanza della varianza dei residui.\nDispersione uniforme ‚Üí ok.\nFunnel o variazioni di ampiezza ‚Üí eteroschedasticit√†.\n\n\n\n\n‚úÖ 4. Residuals vs Leverage\n\nIdentifica osservazioni influenti.\nPunti con alto leverage e residui grandi ‚Üí potrebbero avere impatto eccessivo sul modello.\nDa esaminare singolarmente (possibili outlier o errori)."
  },
  {
    "objectID": "Grafici.html#predicted-vs-actual",
    "href": "Grafici.html#predicted-vs-actual",
    "title": "Analisi dei dati per la psicologia",
    "section": "Predicted vs Actual",
    "text": "Predicted vs Actual\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\nüîÆ Interpretazione del grafico Predicted vs Actual\n\n\n‚úÖ 1. Cosa mostra questo grafico?\n\nConfronta i valori previsti dal modello (asse X) con i valori osservati reali (asse Y).\nUtile per valutare l‚Äôaccuratezza del modello: quanto bene le previsioni replicano i dati osservati?\n\n\n\n\n‚úÖ 2. Interpretazione ideale\n\nI punti dovrebbero allinearsi lungo la diagonale (linea y = x).\nUna buona aderenza alla diagonale indica:\n\nPrevisioni accurate\nBuona capacit√† del modello di rappresentare i dati reali\n\n\n\n\n\n‚úÖ 3. Segnali da osservare\n\n\n\n\n\n\n\nComportamento dei punti\nCosa indica\n\n\n\n\n‚úÖ Allineamento lungo la diagonale\nPrevisioni vicine ai valori reali (ottimo)\n\n\n‚ùå Deviazione sistematica\nBias del modello (sottostima o sovrastima)\n\n\n‚ùå Dispersione elevata\nPrevisioni poco precise\n\n\n‚ùå Pattern curvi o gruppi\nModello mal specificato o relazioni non lineari\n\n\n\n\n\n\n‚úÖ 4. Quando usarlo?\n\nIn ogni modello di regressione o predizione (lineare, logistico, machine learning).\nPer valutare la qualit√† globale delle previsioni."
  },
  {
    "objectID": "Grafici.html#curva-di-potenza",
    "href": "Grafici.html#curva-di-potenza",
    "title": "Analisi dei dati per la psicologia",
    "section": "Curva di potenza",
    "text": "Curva di potenza\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n‚ö° Interpretazione della Curva di Potenza (Power Curve)\n\n\n‚úÖ 1. Cos‚Äô√® la curva di potenza?\n\nMostra come la probabilit√† di rilevare un effetto reale (potenza statistica) varia al cambiare della dimensione dell‚Äôeffetto o del numero di osservazioni.\nAsse X: Dimensione dell‚Äôeffetto o dimensione del campione (n)\nAsse Y: Potenza statistica (P = 1 - Œ≤), cio√® la probabilit√† di rifiutare correttamente H‚ÇÄ.\n\n\n\n\n‚úÖ 2. Interpretazione dei valori\n\nUna potenza ‚â• 0.80 (80%) √® considerata adeguata ‚Üí bassa probabilit√† di errore di tipo II.\nValori pi√π bassi indicano scarsa sensibilit√† del test ‚Üí alto rischio di non rilevare un effetto reale.\nLa curva mostra quanta potenza si guadagna aumentando il campione o l‚Äôeffetto.\n\n\n\n\n‚úÖ 3. Cosa osservare nella curva\n\n\n\n\n\n\n\nForma della curva\nInterpretazione\n\n\n\n\nüìà Curva crescente e appiattita\nAll‚Äôaumentare di n, la potenza si stabilizza\n\n\nüéØ Punto in cui P ‚âà 0.80\nSoglia ottimale per scegliere la dimensione campione\n\n\n‚ùó Curva piatta a valori bassi\nEffetto troppo piccolo per essere rilevabile\n\n\n\n\n\n\n‚úÖ 4. Quando usarla?\n\nIn fase di pianificazione dello studio ‚Üí per determinare quanti soggetti servono.\nPer verificare se un test ha potenza sufficiente a rilevare un effetto atteso.\n\n\n\n\nüìå Obiettivo finale\n\nAssicurarsi che il test abbia un‚Äôalta probabilit√† di successo, evitando sprechi di risorse o conclusioni false negative."
  },
  {
    "objectID": "output.html",
    "href": "output.html",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "",
    "text": "Tabella degli indici statistici inferenziali\n\n\n\n\n\n\n\n\n\n\nNome\nSimbolo\nFormula\nDescrizione\nInterpretazione\nUtilizzo\n\n\n\n\nEta quadrato\n\\(\\eta^2\\)\n\\(\\frac{SS_{\\text{effetto}}}{SS_{\\text{totale}}}\\)\nQuota di varianza spiegata da un effetto\n0.01 = piccolo, 0.06 = medio, 0.14+ = grande\nANOVA, ANCOVA\n\n\nR quadrato\n\\(R^2\\)\n\\(1 - \\frac{SS_{\\text{residuo}}}{SS_{\\text{totale}}}\\)\nVarianza spiegata dal modello\n0‚Äì1; pi√π alto √® meglio\nRegressione lineare\n\n\nCorrelazione\n\\(r\\)\n\\(\\frac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y}\\)\nRelazione lineare tra due variabili\n-1 a +1\nAnalisi bivariata\n\n\nCohen‚Äôs d\n\\(d\\)\n\\(\\frac{\\bar{x}_1 - \\bar{x}_2}{s_p}\\)\nDifferenza standardizzata tra due medie\n0.2 = piccolo, 0.5 = medio, 0.8+ = grande\nTest t, esperimenti\n\n\nTest t\n\\(t\\)\n\\(\\frac{\\bar{x}_1 - \\bar{x}_2}{SE}\\)\nConfronto tra due medie\nValori alti ‚Üí significativi\nInferenza su medie\n\n\nTest F\n\\(F\\)\n\\(\\frac{MS_{\\text{modello}}}{MS_{\\text{errore}}}\\)\nConfronta varianze spiegate vs.¬†non spiegate\n&gt;1 e p &lt; .05 ‚Üí effetto significativo\nANOVA, regressione\n\n\nAIC\nAIC\n\\(2k - 2\\ln(L)\\)\nBilancia adattamento e complessit√†\nPi√π basso = migliore\nScelta tra modelli\n\n\nBIC\nBIC\n\\(\\ln(n)k - 2\\ln(L)\\)\nCome AIC ma pi√π penalizzante\nPi√π basso = preferito\nModelli complessi\n\n\nLOO-CV\nLOO\nMedia log-verosimiglianze lasciando fuori 1 osservazione\nValidazione predittiva modello\nPi√π alto = migliore\nBayes, modelli predittivi\n\n\nZ-score\n\\(z\\)\n\\(\\frac{x - \\mu}{\\sigma}\\)\nDistanza standardizzata da media\n|z| &gt; 1.96 ‚Üí significativo\nStandardizzazione, normalit√†\n\n\np-value\n\\(p\\)\n-\nProbabilit√† di osservare un dato sotto \\(H_0\\)\np &lt; 0.05 ‚Üí significativo\nOgni test d‚Äôipotesi\n\n\nAlpha\n\\(\\alpha\\)\n-\nSoglia di significativit√†\nTipicamente 0.05\nDecisione inferenziale\n\n\nBayes Factor\n\\(BF_{10}\\)\n\\(\\frac{P(D \\mid M_1)}{P(D \\mid M_0)}\\)\nSupporto relativo per \\(H_1\\) contro \\(H_0\\)\n&gt;1 = favorevole a \\(H_1\\)\nStatistica bayesiana\n\n\nDeviance\n-\n\\(-2(\\log L_{\\text{modello}} - \\log L_{\\text{saturo}})\\)\nMisura bont√† del fit nei GLM\nPi√π basso = meglio\nGLM, logistica, Poisson\n\n\nWAIC\nWAIC\nSomma penalizzata di log-verosimiglianze\nCriterio bayesiano di selezione modelli\nPi√π basso = migliore\nBayes\n\n\nICC\nICC\n\\(\\frac{\\sigma^2_{tra}}{\\sigma^2_{tra} + \\sigma^2_{intra}}\\)\nAffidabilit√† intra-classe\n0‚Äì1; alto = coerente\nPsicometria, modelli misti"
  },
  {
    "objectID": "output.html#indici-di-statistica-inferenziale",
    "href": "output.html#indici-di-statistica-inferenziale",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "",
    "text": "Tabella degli indici statistici inferenziali\n\n\n\n\n\n\n\n\n\n\nNome\nSimbolo\nFormula\nDescrizione\nInterpretazione\nUtilizzo\n\n\n\n\nEta quadrato\n\\(\\eta^2\\)\n\\(\\frac{SS_{\\text{effetto}}}{SS_{\\text{totale}}}\\)\nQuota di varianza spiegata da un effetto\n0.01 = piccolo, 0.06 = medio, 0.14+ = grande\nANOVA, ANCOVA\n\n\nR quadrato\n\\(R^2\\)\n\\(1 - \\frac{SS_{\\text{residuo}}}{SS_{\\text{totale}}}\\)\nVarianza spiegata dal modello\n0‚Äì1; pi√π alto √® meglio\nRegressione lineare\n\n\nCorrelazione\n\\(r\\)\n\\(\\frac{\\text{cov}(X,Y)}{\\sigma_X \\sigma_Y}\\)\nRelazione lineare tra due variabili\n-1 a +1\nAnalisi bivariata\n\n\nCohen‚Äôs d\n\\(d\\)\n\\(\\frac{\\bar{x}_1 - \\bar{x}_2}{s_p}\\)\nDifferenza standardizzata tra due medie\n0.2 = piccolo, 0.5 = medio, 0.8+ = grande\nTest t, esperimenti\n\n\nTest t\n\\(t\\)\n\\(\\frac{\\bar{x}_1 - \\bar{x}_2}{SE}\\)\nConfronto tra due medie\nValori alti ‚Üí significativi\nInferenza su medie\n\n\nTest F\n\\(F\\)\n\\(\\frac{MS_{\\text{modello}}}{MS_{\\text{errore}}}\\)\nConfronta varianze spiegate vs.¬†non spiegate\n&gt;1 e p &lt; .05 ‚Üí effetto significativo\nANOVA, regressione\n\n\nAIC\nAIC\n\\(2k - 2\\ln(L)\\)\nBilancia adattamento e complessit√†\nPi√π basso = migliore\nScelta tra modelli\n\n\nBIC\nBIC\n\\(\\ln(n)k - 2\\ln(L)\\)\nCome AIC ma pi√π penalizzante\nPi√π basso = preferito\nModelli complessi\n\n\nLOO-CV\nLOO\nMedia log-verosimiglianze lasciando fuori 1 osservazione\nValidazione predittiva modello\nPi√π alto = migliore\nBayes, modelli predittivi\n\n\nZ-score\n\\(z\\)\n\\(\\frac{x - \\mu}{\\sigma}\\)\nDistanza standardizzata da media\n|z| &gt; 1.96 ‚Üí significativo\nStandardizzazione, normalit√†\n\n\np-value\n\\(p\\)\n-\nProbabilit√† di osservare un dato sotto \\(H_0\\)\np &lt; 0.05 ‚Üí significativo\nOgni test d‚Äôipotesi\n\n\nAlpha\n\\(\\alpha\\)\n-\nSoglia di significativit√†\nTipicamente 0.05\nDecisione inferenziale\n\n\nBayes Factor\n\\(BF_{10}\\)\n\\(\\frac{P(D \\mid M_1)}{P(D \\mid M_0)}\\)\nSupporto relativo per \\(H_1\\) contro \\(H_0\\)\n&gt;1 = favorevole a \\(H_1\\)\nStatistica bayesiana\n\n\nDeviance\n-\n\\(-2(\\log L_{\\text{modello}} - \\log L_{\\text{saturo}})\\)\nMisura bont√† del fit nei GLM\nPi√π basso = meglio\nGLM, logistica, Poisson\n\n\nWAIC\nWAIC\nSomma penalizzata di log-verosimiglianze\nCriterio bayesiano di selezione modelli\nPi√π basso = migliore\nBayes\n\n\nICC\nICC\n\\(\\frac{\\sigma^2_{tra}}{\\sigma^2_{tra} + \\sigma^2_{intra}}\\)\nAffidabilit√† intra-classe\n0‚Äì1; alto = coerente\nPsicometria, modelli misti"
  },
  {
    "objectID": "output.html#distribuzione-normale",
    "href": "output.html#distribuzione-normale",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Distribuzione Normale",
    "text": "Distribuzione Normale\n\n\n\n\n\n\n\n\n\n\n\n\nPropriet√† della normale\n\n\n\n\n\n\nPropriet√†\nDettaglio\n\n\n\n\nSimmetria\nSimmetrica rispetto alla media \\(\\mu\\)\n\n\nUnimodale\nHa un solo picco (moda = media = mediana)\n\n\nAsintotica\nLe code si avvicinano all‚Äôasse x ma non lo toccano mai\n\n\nArea totale sotto la curva\n1\n\n\nPercentili importanti\n68% dei dati entro 1œÉ, 95% entro 2œÉ, 99.7% entro 3œÉ (regola empirica)"
  },
  {
    "objectID": "output.html#distribuzione-t-di-student",
    "href": "output.html#distribuzione-t-di-student",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Distribuzione t di Student",
    "text": "Distribuzione t di Student\n\n\n\n\n\n\n\n\n\n\n\n\nPropriet√† della t di Student\n\n\n\n\n\n\nPropriet√†\nDettaglio\n\n\n\n\nSimmetrica\n√à centrata su 0, come la normale\n\n\nCode pi√π pesanti\nMaggiore probabilit√† di valori estremi rispetto alla normale\n\n\nDipende da \\(df = n-1\\)\n\\(df=n‚àí1\\) Gradi di libert√†, variano con la dimensione del campione\n\n\nConverge alla normale\nPer \\(( n \\to \\infty )\\), la distribuzione t diventa una normale standard\n\n\nVarianza\nnon definita per \\(df \\leq 2\\)"
  },
  {
    "objectID": "output.html#distribuzione-f-di-fisher",
    "href": "output.html#distribuzione-f-di-fisher",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Distribuzione F di Fisher",
    "text": "Distribuzione F di Fisher\n\n\n\n\n\n\n\n\n\n\n\n\nPropriet√† della F di Fisher\n\n\n\n\n\n\nPropriet√†\nDettaglio\n\n\n\n\nDominio\nSolo valori positivi: \\(F ‚àà [0, +‚àû)\\)\n\n\nAsimmetrica\nHa una coda destra lunga, soprattutto per piccoli d.f.\n\n\nDipende da due d.f.\nNumeratore \\(d_1\\), denominatore \\(d_2\\)\n\n\nMedia\n\\(\\frac{d_2} {d_2 - 2}\\), se \\(d_2 &gt; 2\\)\n\n\nModa\n\\(\\frac {(d_1 - 2) d_2}{d_1 (d_2 + 2)}\\), se \\(d_1 &gt; 2\\)\n\n\nVarianza\nFormula complessa; esiste solo per \\(d_2 &gt; 4\\)\n\n\nNon simmetrica\nSpostata a destra; con d.f. grandi tende alla distribuzione normale"
  },
  {
    "objectID": "output.html#distribuzione-chi-quadrato",
    "href": "output.html#distribuzione-chi-quadrato",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Distribuzione Chi-quadrato",
    "text": "Distribuzione Chi-quadrato\n\n\n\n\n\n\n\n\n\n\n\n\nPropriet√† della Chisq\n\n\n\n\n\n\nPropriet√†\nDettaglio\n\n\n\n\nDominio\nSolo valori positivi: \\(\\chi^2 \\in [0, +\\infty)\\)\n\n\nAsimmetrica\nDistribuzione asimmetrica a destra, pi√π simmetrica all‚Äôaumentare dei gradi di libert√†\n\n\nDipende da d.f.\nUnico parametro: gradi di libert√† \\(k\\)\n\n\nMedia\n\\(\\mu = k\\)\n\n\nVarianza\n\\(\\sigma^2 = 2k\\)\n\n\nModa\n\\(k - 2\\), se \\(k \\geq 2\\)\n\n\nSimmetria\nPer \\(k &gt; 30\\) tende alla normale: \\(\\mathcal{N}(k, 2k)\\)\n\n\nSomma di quadrati\n\\(\\chi^2 = \\sum_{i=1}^{k} Z_i^2\\), con \\(Z_i \\sim \\mathcal{N}(0, 1)\\)"
  },
  {
    "objectID": "output.html#assunti-del-modello-di-regressione",
    "href": "output.html#assunti-del-modello-di-regressione",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Assunti del modello di regressione",
    "text": "Assunti del modello di regressione\nCome tutti i modelli statistici, anche quello di regressione lineare si basa su una serie di assunti che devono essere rispettati ovvero:\n\nIndipendenza dei predittori dall‚Äôerrore. Le X sono misurate senza errore. Tale assunto √® evidente nei disegni sperimentali in cui i valori dei predittori sono sotto il diretto controllo dello sperimentatore. Nel resto dei casi i valori delle X sono ottenuti come risultato di un campionamento, pertanto questa assunzione implica che i predittori e gli errori siano indipendenti nella popolazione da cui vengono estratti.\nIndipendenza delle osservazioni. Tutte le coppie di errori \\(\\varepsilon i\\) ed \\(\\varepsilon j\\) sono tra loro indipendenti per ogni \\(i = j\\). Detto in altri termini significa semplicemente che le osservazioni sono state campionate in modo indipendente l‚Äôuna dall‚Äôaltra.\nLinearit√†. Il valore atteso dell‚Äôerrore per un dato valore di X2 √® zero: \\(E(\\varepsilon i) = E(\\varepsilon|xi) = 0\\). In pratica significa che il valore atteso della variabile dipendente, \\(E(Y)\\), √® una funzione lineare del predittore.\nNormalit√†. Gli errori sono distribuiti normalmente: \\(\\varepsilon i ‚àº N(0,œÉ2)\\). Questo implica che anche la distribuzione di yi sia normale con media pari a \\(\\beta0 + \\beta xi\\).\nVarianza costante. La varianza degli errori √® costante per qualunque valore di X : \\(V(\\varepsilon|xi) = œÉ2\\). Anche in questo caso la varianza costante negli errori implica valori costanti anche della variabile Y per ciascun valore dato di X."
  },
  {
    "objectID": "output.html#interpretazione-test-parametrici",
    "href": "output.html#interpretazione-test-parametrici",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Interpretazione test parametrici",
    "text": "Interpretazione test parametrici\n\n\n\n\n\n\n\n\n\n\nTest\nTipo di Dato\nAssunti\nVerifica Assunti\nInterpretazione (p-value)\n\n\n\n\nt-test indipendenti\nContinua\nNormalit√†, omogeneit√† varianze, indipendenza\nShapiro-Wilk, Levene\np &lt; 0.05: differenza tra gruppi\n\n\nt-test appaiati\nContinua (paired)\nNormalit√† delle differenze\nShapiro-Wilk su differenze\np &lt; 0.05: differenza tra condizioni\n\n\nANOVA a una via\nContinua + gruppi\nNormalit√†, omogeneit√† varianze, indipendenza\nShapiro-Wilk, Levene, Bartlett\np &lt; 0.05: almeno un gruppo differente\n\n\nANOVA a due vie\nContinua + 2 fattori\nCome sopra + assenza di interazioni spurie\nVerifica grafica, Levene, Bartlett\np &lt; 0.05: effetti principali/interazione significativi\n\n\nMANOVA\nContinua multivariata\nMultinormalit√†, omogeneit√† covarianze, assenza multicollinearit√†\nBox‚Äôs M, grafici, Bartlett\np &lt; 0.05: almeno una differenza multivariata tra i gruppi\n\n\nRegressione lineare semplice\nContinua\nLinearit√†, normalit√† residui, omoscedasticit√†, indipendenza residui\nQ-Q plot, Breusch-Pagan, Durbin-Watson, scatter plot\np &lt; 0.05: predittore significativo\n\n\nRegressione multipla\nContinua\nIdem sopra + no multicollinearit√†\nVIF, Condition Index\np &lt; 0.05: almeno un predittore √® significativo\n\n\nTest F per varianze\nContinua\nNormalit√†, indipendenza\nShapiro-Wilk, disegno\np &lt; 0.05: varianze significativamente diverse\n\n\nZ-test\nContinua, n &gt; 30\nConoscenza œÉ pop, normalit√† (o n grande)\nControllo teorico\np &lt; 0.05: differenza tra media campione e popolazione"
  },
  {
    "objectID": "output.html#interpretazione-test-non-parametrici",
    "href": "output.html#interpretazione-test-non-parametrici",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Interpretazione test NON parametrici",
    "text": "Interpretazione test NON parametrici\n\n\n\n\n\n\n\n\n\n\nTest\nTipo di Dato\nAssunti\nVerifica Assunti\nInterpretazione (p-value)\n\n\n\n\nMann-Whitney U\nOrdinale o continua non normale\nForma simile distribuzioni, indipendenza\nBoxplot, istogrammi\np &lt; 0.05: distribuzioni significativamente diverse\n\n\nWilcoxon signed-rank\nPaired non normali\nSimmetria differenze, osservazioni appaiate\nBoxplot delle differenze\np &lt; 0.05: differenza significativa tra condizioni\n\n\nKruskal-Wallis\nOrdinale / continua\nForma simile, indipendenza\nIstogrammi, boxplot\np &lt; 0.05: almeno un gruppo differente\n\n\nFriedman test\nMisure ripetute ordinali\nOsservazioni appaiate\nDisegno sperimentale\np &lt; 0.05: almeno una condizione differente\n\n\nSpearman‚Äôs rho\nOrdinale o continua\nRelazione monotona, indipendenza\nScatterplot, test monotonia\np &lt; 0.05: correlazione significativa\n\n\nKendall‚Äôs tau\nOrdinale, piccoli campioni\nRelazione monotona, indipendenza\nScatterplot, test monotonia\np &lt; 0.05: correlazione significativa\n\n\nChi-quadro (indipendenza)\nCategoriale\nFrequenze attese ‚â• 5, indipendenza\nTabella contingenza, conteggi\np &lt; 0.05: associazione significativa\n\n\nTest esatto di Fisher\nCategoriale, n piccolo\nFrequenze molto basse, 2x2\nTabella contingenza\np &lt; 0.05: associazione significativa\n\n\nMcNemar\nCategoriale paired\nOsservazioni appaiate\nTabella 2x2, differenze discordanti\np &lt; 0.05: cambiamento significativo pre/post"
  },
  {
    "objectID": "output.html#interpretazione-test-per-assunti",
    "href": "output.html#interpretazione-test-per-assunti",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Interpretazione test per assunti",
    "text": "Interpretazione test per assunti\n\n\n\n\n\n\n\n\n\nTest\nAssunto\nUso\nInterpretazione (p-value)\n\n\n\n\nShapiro-Wilk / Kolmogorov\nNormalit√†\nNormalit√† delle variabili o residui\np &lt; 0.05: dati NON normali\n\n\nLevene / Bartlett\nOmogeneit√† varianze\nTest ANOVA, t-test indipendenti\np &lt; 0.05: varianze NON omogenee\n\n\nMauchly\nSfericit√†\nMisure ripetute\np &lt; 0.05: sfericit√† VIOLATA\n\n\nBreusch-Pagan / White\nOmoscedasticit√† residui\nRegressione\np &lt; 0.05: eteroscedasticit√† presente\n\n\nDurbin-Watson\nIndipendenza residui\nSerie temporali / regressione\n‚â† 2: autocorrelazione presente\n\n\nVIF / Tolerance\nMulticollinearit√†\nRegressione multipla\nVIF &gt; 10: multicollinearit√† problematicamente alta"
  },
  {
    "objectID": "output.html#schema-decisionale-tipo-di-effetti-casuali-vs-grafico-atteso",
    "href": "output.html#schema-decisionale-tipo-di-effetti-casuali-vs-grafico-atteso",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Schema decisionale: tipo di effetti casuali vs grafico atteso",
    "text": "Schema decisionale: tipo di effetti casuali vs grafico atteso\nüîπ Formula del modello: y ~ x + ( ? | gruppo )\n\n\n\n\n\n\n\n\n\nSpecifica nella formula\nIntercette variabili?\nPendenze variabili?\nTipo di grafico\n\n\n\n\n(1 | gruppo)\n‚úÖ S√¨\n‚ùå No\nIntercette variabili\n\n\n(0 + x | gruppo)\n‚ùå No\n‚úÖ S√¨\nSolo pendenze variabili (senza shift)\n\n\n(1 + x | gruppo)\n‚úÖ S√¨\n‚úÖ S√¨\nIntercette e pendenze variabili\n\n\n(1 | gruppo) + (0 + x | gruppo)\n‚úÖ S√¨\n‚úÖ S√¨\nIntercette e pendenze variabili (specificati separatamente)\n\n\n(x | gruppo)\n‚úÖ S√¨\n‚úÖ S√¨\n‚úîÔ∏è Sintassi abbreviata per (1 + x | gruppo)\n\n\n\nNota bene\n\nSe pendenze variabili sono presenti ‚Üí le linee nei grafici hanno inclinazioni diverse per ciascun gruppo.\nSe solo intercette variano ‚Üí tutte le linee hanno stessa inclinazione, ma partono da livelli diversi."
  },
  {
    "objectID": "output.html#lettura-output",
    "href": "output.html#lettura-output",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Lettura output",
    "text": "Lettura output\n\nMatrice PSI (Œ®) - effetti casuali\n\n\n\n  \n\n\n            (Intercept)        x1        x2\n(Intercept)   0.7483970 0.2902670 0.4767351\nx1            0.2902670 0.7659657 0.3129400\nx2            0.4767351 0.3129400 1.6889789\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\n\nüîç Interpreta la matrice\n\nDiagonale (verso sinistra) - varianze (quanto variano gli effetti casuali per intercetta, x1, x2)\nFuori diagonale - covarianze (come variano insieme gli effetti nei gruppi)\n\n\n\n \n\n\n\nRegressione lineare\n\n\n\n  \n\n\n\nCall:\nlm(formula = weight ~ height, data = dati)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.5830 -3.0758 -0.3937  2.6129 14.8068 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -21.7935     8.2313  -2.648  0.00945 ** \nheight        0.9634     0.0481  20.031  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.368 on 98 degrees of freedom\nMultiple R-squared:  0.8037,    Adjusted R-squared:  0.8017 \nF-statistic: 401.2 on 1 and 98 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nCall: Specifica la formula usata: weight ~ height.\nResidui: Differenze tra i valori osservati e quelli stimati. Distribuiti idealmente attorno a 0.\nCoefficienti:\n\nIntercept: valore teorico del peso quando l‚Äôaltezza √® zero (non realistico, ma serve al modello).\nHeight: effetto medio dell‚Äôaltezza sul peso (es. +0.987 kg per ogni cm in pi√π).\n\nErrore standard residuo: misura la dispersione dei residui. Pi√π basso = stime pi√π precise.\nR¬≤ / Adjusted R¬≤: percentuale di variabilit√† spiegata dal modello (con e senza correzione).\nF-statistic: test globale di significativit√† del modello. Se p-value √® basso ‚Üí modello significativo.\n\n\n\n\n \n\n\n\nRegressione lineare - effetti fissi/random\n\n\n\n  \n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: mpg ~ hp + (1 + hp | cyl)\n   Data: mtcars\n\nREML criterion at convergence: 170.9\n\nScaled residuals: \n     Min       1Q   Median       3Q      Max \n-1.65419 -0.63457 -0.03825  0.48872  2.15522 \n\nRandom effects:\n Groups   Name        Variance  Std.Dev. Corr \n cyl      (Intercept) 27.571143 5.25082       \n          hp           0.000613 0.02476  -1.00\n Residual              9.401205 3.06614       \nNumber of obs: 32, groups:  cyl, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept) 26.63970    3.39879   7.838\nhp          -0.05354    0.01680  -3.186\n\nCorrelation of Fixed Effects:\n   (Intr)\nhp -0.975\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nüîπ Effetti fissi (Fixed effects)\n\n(Intercept):\nQuesto valore rappresenta la stima del consumo medio di carburante (mpg) quando i cavalli (hp) sono pari a 0. Naturalmente, non √® realistico avere 0 cavalli, ma questo valore serve come punto di riferimento nel modello.\nhp:\nIn media, all‚Äôaumentare di 1 unit√† nei cavalli (hp), ci si aspetta una diminuzione di 0.068 miglia per gallone nel consumo (mpg), tenendo conto delle variazioni tra gruppi (cyl).\n\n\n\n\nüîπ Effetti casuali (Random effects)\n\nIl termine (1 + hp | cyl) specifica che sia l‚Äôintercetta che il coefficiente di hp variano tra i gruppi definiti da numero di cilindri (cyl).\nVarianza dell‚Äôintercetta:\nIndica che esiste una forte variabilit√† nel livello medio di mpg tra i gruppi di cilindrata.\nVarianza della pendenza di hp:\nSignifica che l‚Äôeffetto di hp su mpg cambia leggermente tra i gruppi, ma la variabilit√† √® pi√π contenuta rispetto all‚Äôintercetta.\nCorrelazione intercetta-pendenza:\nL‚Äôoutput mostra una correlazione negativa (-1.00) tra intercetta e pendenza nei gruppi cyl, quindi gruppi con mpg medi pi√π alti tendono ad avere pendenze pi√π ripide (pi√π negative)\n\n\n\n\nüîπ Errore residuo (Residual variance)\n\nVarianza residua:\nRappresenta la variabilit√† nei valori di mpg non spiegata n√© dagli effetti fissi n√© da quelli casuali. Questo √® l‚Äôerrore ‚Äúinterno‚Äù al gruppo.\n\n\n\n\n\n \n\n\n\nAnalisi della varianza\n\n\n\n  \n\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ngroup        2   1720   860.3   31.37 5.53e-11 ***\nResiduals   87   2386    27.4                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nObiettivo: verificare se almeno un gruppo ha una media significativamente diversa.\nFormula: values ~ group confronta le medie dei gruppi A, B e C.\nGradi di libert√† (DF):\n\nTra gruppi: k - 1 ‚Üí 3 ‚àí 1 = 2\nEntro gruppi (residuali): n - k ‚Üí 90 ‚àí 3 = 87\n\nSomma dei quadrati (Sum Sq):\n\nBetween Groups: variabilit√† spiegata dalle differenze tra le medie\nResiduals: variabilit√† interna ai gruppi\n\nMedia dei quadrati (Mean Sq): Sum Sq / DF\nF-value: rapporto tra varianza spiegata e residua\nPr(&gt;F):\n\nSe &lt; 0.05 ‚Üí almeno un gruppo ha media significativamente diversa\nSe &gt; 0.05 ‚Üí nessuna differenza significativa\n\n\n\n\n\n \n\n\n\nConfronto tra modelli (AIC)\n\n\n\n  \n\n\nGlobal model call: lm(formula = mpg ~ wt + hp + qsec + drat, data = mtcars)\n---\nModel selection table \n   (Intrc)  drat       hp    qsec     wt df   logLik   AIC delta weight\n11  37.230       -0.03177         -3.878  4  -74.326 156.7  0.00  0.181\n14  11.390 1.656           0.9462 -4.398  5  -73.352 156.7  0.05  0.176\n13  19.750                 0.9292 -5.048  4  -74.360 156.7  0.07  0.175\n12  29.390 1.615 -0.03223         -3.228  5  -73.366 156.7  0.08  0.174\n16  19.260 1.657 -0.01784  0.5275 -3.708  6  -72.509 157.0  0.36  0.151\n15  27.610       -0.01782  0.5108 -4.359  5  -73.571 157.1  0.49  0.141\n9   37.290                        -5.344  3  -80.015 166.0  9.38  0.002\n10  30.290 1.442                  -4.783  4  -79.484 167.0 10.32  0.001\n4   10.790 4.698 -0.05179                 4  -80.752 169.5 12.85  0.000\n8   17.740 4.429 -0.05797 -0.2841         5  -80.561 171.1 14.47  0.000\n7   48.320       -0.08459 -0.8866         4  -86.170 180.3 23.69  0.000\n3   30.100       -0.06823                 3  -87.619 181.2 24.59  0.000\n6  -27.840 7.309           1.2130         4  -88.026 184.1 27.40  0.000\n2   -7.525 7.678                          3  -92.400 190.8 34.15  0.000\n5   -5.114                 1.4120         3  -99.294 204.6 47.94  0.000\n1   20.090                                2 -102.378 208.8 52.10  0.000\nModels ranked by AIC(x) \n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nObiettivo: confrontare tutti i sottoinsiemi possibili del modello globale per identificare il modello pi√π parsimonioso secondo il criterio AIC.\nColonne principali:\n\nInt, wt, hp, qsec, drat: indicano la presenza o assenza di ciascun termine nel modello.\ndf: numero di parametri stimati nel modello.\nlogLik: log-likelihood del modello.\nAIC: criterio di informazione di Akaike; valori pi√π bassi indicano modelli migliori.\ndelta: differenza tra l‚ÄôAIC del modello corrente e il minimo AIC tra tutti i modelli.\nweight: peso di Akaike, rappresenta la probabilit√† relativa che il modello sia il migliore tra quelli considerati.\n\nInterpretazione dei risultati:\n\nIl modello con delta = 0 √® il migliore secondo l‚ÄôAIC.\nModelli con delta &lt; 2 hanno un supporto sostanziale e possono essere considerati competitivi.\nI pesi di Akaike (weight) possono essere utilizzati per il model averaging o per valutare l‚Äôevidenza relativa a favore di ciascun modello.\n\n\n\n\n\n \n\n\n\nConfronto tra modelli (LOO)\n\n\n\n  \n\n\n              model    looic se_looic  elpd_diff   se_diff\nmod2       mod1: x1 388.6006 12.73663  0.0000000 0.0000000\nmod3    mod2: x1+x2 378.9653 13.38565 -0.9298536 0.5735233\nmod1 mod3: x1+x2+x3 380.8250 13.39839 -4.8176874 3.4359110\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\nSignificato degli indici riportati:\n\nlooic (Leave-One-Out Information Criterion): misura la bont√† predittiva del modello. Valori pi√π bassi indicano migliore performance predittiva.\nse_looic: √® l‚Äôerrore standard associato a looic. Indica l‚Äôincertezza nella stima di looic.\nelpd_diff (expected log predictive density difference): differenza della capacit√† predittiva di ciascun modello rispetto al migliore (quello con elpd_diff = 0). Valori negativi indicano prestazioni inferiori.\nse_diff: errore standard associato a elpd_diff. Serve per valutare la significativit√† della differenza: se elpd_diff √® maggiore di 2√óse_diff, la differenza √® considerata sostanziale.\n\n\nRisultati nel confronto tra modelli:\n\nIl modello mod2: x1 + x2 ha il valore di looic pi√π basso, quindi √® il miglior modello predittivo tra quelli considerati.\nIl modello mod1: x1 √® significativamente peggiore di mod2\nIl modello mod3: x1 + x2 + x3, una differenza non significativa rispetto a mod2. Aggiungere la variabile x3 non migliora in modo rilevante la predizione.\n\nIn sintesi, mod2 √® il miglior compromesso tra semplicit√† e accuratezza predittiva.\n\n\n\n \n\n\n\nChisq Test per modelli annidati\n\n\n\n  \n\n\nData: sleepstudy\nModels:\nm1: Reaction ~ 1 + (1 | Subject)\nm2: Reaction ~ Days + (1 | Subject)\nm3: Reaction ~ Days + I(Days^2) + (1 | Subject)\nm4: Reaction ~ Days + I(Days^2) + I(Days^3) + (1 | Subject)\nm5: Reaction ~ Days + I(Days^2) + I(Days^3) + I(Days^4) + (1 | Subject)\n   npar    AIC    BIC  logLik deviance    Chisq Df Pr(&gt;Chisq)    \nm1    3 1916.5 1926.1 -955.27   1910.5                           \nm2    4 1802.1 1814.8 -897.04   1794.1 116.4624  1     &lt;2e-16 ***\nm3    5 1802.9 1818.9 -896.47   1792.9   1.1349  1     0.2867    \nm4    6 1804.9 1824.1 -896.47   1792.9   0.0094  1     0.9226    \nm5    7 1806.3 1828.6 -896.14   1792.3   0.6599  1     0.4166    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nSono stati confrontati 5 modelli misti annidati:\n\nTutti includono un termine casuale per il soggetto ((1 | Subject)).\nOgni modello aggiunge progressivamente effetti fissi: Days, Days^2, ecc.\n\nLa tabella mostra:\n\nAIC, BIC: criteri di bont√† del modello; valori pi√π bassi sono migliori.\nlogLik: log-verosimiglianza del modello.\nChisq: statistica del test del rapporto di verosimiglianza (LRT).\nDf diff: differenza nei gradi di libert√† tra i modelli.\nPr(&gt;Chisq): p-value del test LRT.\n\nSe il p-value &lt; 0.05 ‚Üí l‚Äôaggiunta della nuova variabile migliora significativamente il modello.\n√à importante usare REML = FALSE per confronti validi tra modelli con effetti fissi diversi.\nL‚Äôultimo modello con miglioramento significativo e AIC basso pu√≤ essere selezionato come finale.\n\n\n\n\n \n\n\n\nStudio di potenza\n\n\n\n  \n\n\n\n     Two Sample Cohen's d \n\n      data.name = Ym and Yf\n      statistic = 0.8856\n         effect = large\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nStatistic: d = 0.8856\nInterpretazione: Effetto grande secondo le soglie di Cohen:\n\npiccolo: ~ 0.2\nmedio: ~ 0.5\ngrande: ~ 0.8\n\n\nQuesto significa che la differenza media tra i gruppi Ym e Yf √® ampia rispetto alla variabilit√† complessiva.\nL‚Äôeffetto √® sufficientemente forte da essere considerato rilevante\n\n\n\n \n\n\n\nErrori di tipo M o S\n\n\n\n  \n\n\n\n    Design Analysis\n\nHypothesized effect:  cohen_d = 0.4 \n\nStudy characteristics:\n   test_method   sample_n1   sample_n2   alternative   sig_level   df\n   two_sample    8           8           greater       0.05        14\n\nInferential risks:\n   power   typeM   typeS\n   0.182   2.887   0    \n\nCritical value(s): cohen_d  =  0.881\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nPotenza: 0.182\nIl test ha solo il 18.2% di probabilit√† di rilevare un effetto vero di d = 0.4 se esiste.\nQuesto valore √® molto inferiore al livello desiderato di 0.80, indicando un alto rischio di falso negativo (errore di tipo II).\nErrore di tipo M (Magnitude): 2.887\nSe ottieni un risultato significativo, √® probabile che l‚Äôeffetto stimato sar√† quasi 3 volte pi√π grande di quello reale.\nQuesto riflette un rischio molto elevato di sovrastimare l‚Äôeffetto in caso di significativit√†.\nErrore di tipo S (Sign): 0\nIl rischio che l‚Äôeffetto significativo abbia segno opposto rispetto a quello reale √® nullo.\nQuesto √® possibile perch√© il test √® unilaterale (‚Äúgreater‚Äù), quindi non considera effetti nel verso opposto.\nValore critico di d: 0.881\nPerch√© il risultato sia significativo a p &lt; 0.05, l‚Äôeffetto osservato dovr√† essere ‚â• 0.881.\nQuesto √® pi√π del doppio dell‚Äôeffetto ipotizzato, il che rende difficile ottenere significativit√† con questo disegno.\n\nüìå Conclusione:\nIl disegno attuale (n = 8 per gruppo) √® sottodimensionato per rilevare un effetto di d = 0.4 con adeguata potenza.\nSono raccomandati campioni pi√π grandi per ridurre il rischio di errore tipo M e aumentare la potenza.\n\n\n\n \n\n\n\nBayes Factor Analysis\n\n\n\n  \n\n\nBayes factor analysis\n--------------\n[1] wt + hp : 17.27075 ¬±0.01%\n\nAgainst denominator:\n  mpg ~ wt \n---\nBayes factor type: BFlinearModel, JZS\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nSono stati confrontati due modelli:\n\nBF1: mpg ~ wt\nBF2: mpg ~ wt + hp\n\nIl Bayes Factor (BF) confronta direttamente la probabilit√† dei dati sotto i due modelli.\nValore calcolato: BF2 / BF1\n\nSe BF &gt; 1 ‚Üí i dati supportano di pi√π il secondo modello.\nSe BF &lt; 1 ‚Üí i dati supportano di pi√π il primo modello.\n\nInterpretazione standard del BF:\n\n1‚Äì3: evidenza debole\n3‚Äì10: evidenza moderata\n(&gt;10): evidenza forte a favore del modello al numeratore\n\nIl BF √® una misura continua della forza di evidenza, a differenza del p-value che si basa su soglie arbitrarie.\n\n\n\n\n \n\n\n\nLog Relative Evidence tra modelli (Bayes Factor)\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMostra interpretazione dettagliata\n\n\n\n\n\nüßæ Interpretazione dell‚ÄôOutput\n\nOgni cella della heatmap rappresenta il logaritmo del Bayes Factor tra due modelli specifici.\nIl colore indica la forza dell‚Äôevidenza:\n\nRosso: evidenza a favore del modello sulla riga rispetto a quello sulla colonna.\nBlu: evidenza a favore del modello sulla colonna rispetto a quello sulla riga.\nBianco: evidenza neutra o trascurabile.\n\nLa scala dei colori √® limitata tra -3 e 3 per facilitare l‚Äôinterpretazione visiva.\nQuesto tipo di visualizzazione consente un confronto diretto e intuitivo tra tutti i modelli considerati.\n\n\n\n\n \n\n\n\nInterpretazione SEM - path Diagram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInterpretazione e schema decisionale per il conteggio dei parametri in un modello SEM\n\n\n\nIl diagramma SEM visualizzato rappresenta una struttura di relazioni tra variabili latenti, variabili osservate, e le associazioni tra di esse. √à possibile utilizzare il diagramma per stimare il numero totale di parametri del modello sulla base della tipologia e direzione delle frecce, nonch√© della presenza di varianze e covarianze.\n\nüìå Categorie principali di parametri da contare\n\nCarichi fattoriali (Loadings)\n\nFrecce direzionali da fattori latenti ‚Üí variabili osservate\n\nNumero: 1 parametro per ciascuna freccia\n\nRegressioni strutturali (Path coefficients)\n\nFrecce direzionali tra variabili latenti o da manifesti a latenti\n\nNumero: 1 parametro per ciascuna freccia\n\nVarianze\n\nRappresentate da semicerchi che si collegano a una singola variabile\n\nOgni variabile latente e ogni variabile manifestata ha una varianza stimata\nNumero: 1 parametro per variabile\n\nCovarianze\n\nRappresentate da frecce curve tra due variabili senza direzione causale (‚ÜîÔ∏é)\n\nSpesso tra variabili latenti o tra errori di misura\n\nNumero: 1 parametro per ciascuna coppia correlata\n\n\n\n\nTipologie di variabili\n\n\n\n\n\n\n\n\nTipo di variabile\nCaratteristiche\nEsempi\n\n\n\n\nEsogena\nNon √® spiegata da altre variabili nel modello\nEt√†, Sesso, Condizione sperimentale\n\n\nEndogena\n√à spiegata da almeno una variabile nel modello\nDepressione, Stress, Prestazione\n\n\n\n\n\n\nDal grafo SEM: come riconoscerle?\n\nFreccia in entrata (‚Üí) = variabile endogena\nSolo frecce in uscita = variabile esogena\nLe variabili latenti possono essere endogene o esogene a seconda del modello\n\n\n\nModello SEM ricorsivo o non ricorsivo\n\n\nüß≠ Schema decisionale (logico):\n\n1. Ci sono relazioni bidirezionali tra variabili endogene?\n\n‚úÖ S√¨ ‚Üí Modello non ricorsivo\n‚ùå No ‚Üí Vai al punto 2\n\n2. Ci sono correlazioni tra gli errori delle variabili endogene?\n\n‚úÖ S√¨ ‚Üí Modello non ricorsivo\n‚ùå No ‚Üí Modello ricorsivo\n\n\n\nüß† Definizioni:\n\nRicorsivo:\n\nNessuna retroazione tra variabili endogene\nNessuna correlazione tra gli errori di variabili endogene\n\nNon ricorsivo:\n\nFeedback o relazioni bidirezionali\nErrori correlati tra variabili endogene"
  },
  {
    "objectID": "output.html#interpretazione-delloutput",
    "href": "output.html#interpretazione-delloutput",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nCall: Specifica la formula usata: weight ~ height.\nResidui: Differenze tra i valori osservati e quelli stimati. Distribuiti idealmente attorno a 0.\nCoefficienti:\n\nIntercept: valore teorico del peso quando l‚Äôaltezza √® zero (non realistico, ma serve al modello).\nHeight: effetto medio dell‚Äôaltezza sul peso (es. +0.987 kg per ogni cm in pi√π).\n\nErrore standard residuo: misura la dispersione dei residui. Pi√π basso = stime pi√π precise.\nR¬≤ / Adjusted R¬≤: percentuale di variabilit√† spiegata dal modello (con e senza correzione).\nF-statistic: test globale di significativit√† del modello. Se p-value √® basso ‚Üí modello significativo."
  },
  {
    "objectID": "output.html#interpretazione-delloutput-1",
    "href": "output.html#interpretazione-delloutput-1",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nüîπ Effetti fissi (Fixed effects)\n\n(Intercept):\nQuesto valore rappresenta la stima del consumo medio di carburante (mpg) quando i cavalli (hp) sono pari a 0. Naturalmente, non √® realistico avere 0 cavalli, ma questo valore serve come punto di riferimento nel modello.\nhp:\nIn media, all‚Äôaumentare di 1 unit√† nei cavalli (hp), ci si aspetta una diminuzione di 0.068 miglia per gallone nel consumo (mpg), tenendo conto delle variazioni tra gruppi (cyl).\n\n\n\n\nüîπ Effetti casuali (Random effects)\n\nIl termine (1 + hp | cyl) specifica che sia l‚Äôintercetta che il coefficiente di hp variano tra i gruppi definiti da numero di cilindri (cyl).\nVarianza dell‚Äôintercetta:\nIndica che esiste una forte variabilit√† nel livello medio di mpg tra i gruppi di cilindrata.\nVarianza della pendenza di hp:\nSignifica che l‚Äôeffetto di hp su mpg cambia leggermente tra i gruppi, ma la variabilit√† √® pi√π contenuta rispetto all‚Äôintercetta.\nCorrelazione intercetta-pendenza:\nL‚Äôoutput mostra una correlazione negativa (-1.00) tra intercetta e pendenza nei gruppi cyl, quindi gruppi con mpg medi pi√π alti tendono ad avere pendenze pi√π ripide (pi√π negative)\n\n\n\n\nüîπ Errore residuo (Residual variance)\n\nVarianza residua:\nRappresenta la variabilit√† nei valori di mpg non spiegata n√© dagli effetti fissi n√© da quelli casuali. Questo √® l‚Äôerrore ‚Äúinterno‚Äù al gruppo."
  },
  {
    "objectID": "output.html#interpretazione-delloutput-2",
    "href": "output.html#interpretazione-delloutput-2",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nObiettivo: verificare se almeno un gruppo ha una media significativamente diversa.\nFormula: values ~ group confronta le medie dei gruppi A, B e C.\nGradi di libert√† (DF):\n\nTra gruppi: k - 1 ‚Üí 3 ‚àí 1 = 2\nEntro gruppi (residuali): n - k ‚Üí 90 ‚àí 3 = 87\n\nSomma dei quadrati (Sum Sq):\n\nBetween Groups: variabilit√† spiegata dalle differenze tra le medie\nResiduals: variabilit√† interna ai gruppi\n\nMedia dei quadrati (Mean Sq): Sum Sq / DF\nF-value: rapporto tra varianza spiegata e residua\nPr(&gt;F):\n\nSe &lt; 0.05 ‚Üí almeno un gruppo ha media significativamente diversa\nSe &gt; 0.05 ‚Üí nessuna differenza significativa"
  },
  {
    "objectID": "output.html#interpretazione-delloutput-3",
    "href": "output.html#interpretazione-delloutput-3",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nObiettivo: confrontare tutti i sottoinsiemi possibili del modello globale per identificare il modello pi√π parsimonioso secondo il criterio AIC.\nColonne principali:\n\nInt, wt, hp, qsec, drat: indicano la presenza o assenza di ciascun termine nel modello.\ndf: numero di parametri stimati nel modello.\nlogLik: log-likelihood del modello.\nAIC: criterio di informazione di Akaike; valori pi√π bassi indicano modelli migliori.\ndelta: differenza tra l‚ÄôAIC del modello corrente e il minimo AIC tra tutti i modelli.\nweight: peso di Akaike, rappresenta la probabilit√† relativa che il modello sia il migliore tra quelli considerati.\n\nInterpretazione dei risultati:\n\nIl modello con delta = 0 √® il migliore secondo l‚ÄôAIC.\nModelli con delta &lt; 2 hanno un supporto sostanziale e possono essere considerati competitivi.\nI pesi di Akaike (weight) possono essere utilizzati per il model averaging o per valutare l‚Äôevidenza relativa a favore di ciascun modello."
  },
  {
    "objectID": "output.html#interpretazione-delloutput-4",
    "href": "output.html#interpretazione-delloutput-4",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\nSignificato degli indici riportati:\n\nlooic (Leave-One-Out Information Criterion): misura la bont√† predittiva del modello. Valori pi√π bassi indicano migliore performance predittiva.\nse_looic: √® l‚Äôerrore standard associato a looic. Indica l‚Äôincertezza nella stima di looic.\nelpd_diff (expected log predictive density difference): differenza della capacit√† predittiva di ciascun modello rispetto al migliore (quello con elpd_diff = 0). Valori negativi indicano prestazioni inferiori.\nse_diff: errore standard associato a elpd_diff. Serve per valutare la significativit√† della differenza: se elpd_diff √® maggiore di 2√óse_diff, la differenza √® considerata sostanziale.\n\n\nRisultati nel confronto tra modelli:\n\nIl modello mod2: x1 + x2 ha il valore di looic pi√π basso, quindi √® il miglior modello predittivo tra quelli considerati.\nIl modello mod1: x1 √® significativamente peggiore di mod2\nIl modello mod3: x1 + x2 + x3, una differenza non significativa rispetto a mod2. Aggiungere la variabile x3 non migliora in modo rilevante la predizione.\n\nIn sintesi, mod2 √® il miglior compromesso tra semplicit√† e accuratezza predittiva."
  },
  {
    "objectID": "output.html#interpretazione-delloutput-5",
    "href": "output.html#interpretazione-delloutput-5",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nSono stati confrontati 5 modelli misti annidati:\n\nTutti includono un termine casuale per il soggetto ((1 | Subject)).\nOgni modello aggiunge progressivamente effetti fissi: Days, Days^2, ecc.\n\nLa tabella mostra:\n\nAIC, BIC: criteri di bont√† del modello; valori pi√π bassi sono migliori.\nlogLik: log-verosimiglianza del modello.\nChisq: statistica del test del rapporto di verosimiglianza (LRT).\nDf diff: differenza nei gradi di libert√† tra i modelli.\nPr(&gt;Chisq): p-value del test LRT.\n\nSe il p-value &lt; 0.05 ‚Üí l‚Äôaggiunta della nuova variabile migliora significativamente il modello.\n√à importante usare REML = FALSE per confronti validi tra modelli con effetti fissi diversi.\nL‚Äôultimo modello con miglioramento significativo e AIC basso pu√≤ essere selezionato come finale."
  },
  {
    "objectID": "output.html#interpretazione-delloutput-6",
    "href": "output.html#interpretazione-delloutput-6",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nStatistic: d = 0.8856\nInterpretazione: Effetto grande secondo le soglie di Cohen:\n\npiccolo: ~ 0.2\nmedio: ~ 0.5\ngrande: ~ 0.8\n\n\nQuesto significa che la differenza media tra i gruppi Ym e Yf √® ampia rispetto alla variabilit√† complessiva.\nL‚Äôeffetto √® sufficientemente forte da essere considerato rilevante"
  },
  {
    "objectID": "output.html#interpretazione-delloutput-7",
    "href": "output.html#interpretazione-delloutput-7",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nPotenza: 0.182\nIl test ha solo il 18.2% di probabilit√† di rilevare un effetto vero di d = 0.4 se esiste.\nQuesto valore √® molto inferiore al livello desiderato di 0.80, indicando un alto rischio di falso negativo (errore di tipo II).\nErrore di tipo M (Magnitude): 2.887\nSe ottieni un risultato significativo, √® probabile che l‚Äôeffetto stimato sar√† quasi 3 volte pi√π grande di quello reale.\nQuesto riflette un rischio molto elevato di sovrastimare l‚Äôeffetto in caso di significativit√†.\nErrore di tipo S (Sign): 0\nIl rischio che l‚Äôeffetto significativo abbia segno opposto rispetto a quello reale √® nullo.\nQuesto √® possibile perch√© il test √® unilaterale (‚Äúgreater‚Äù), quindi non considera effetti nel verso opposto.\nValore critico di d: 0.881\nPerch√© il risultato sia significativo a p &lt; 0.05, l‚Äôeffetto osservato dovr√† essere ‚â• 0.881.\nQuesto √® pi√π del doppio dell‚Äôeffetto ipotizzato, il che rende difficile ottenere significativit√† con questo disegno.\n\nüìå Conclusione:\nIl disegno attuale (n = 8 per gruppo) √® sottodimensionato per rilevare un effetto di d = 0.4 con adeguata potenza.\nSono raccomandati campioni pi√π grandi per ridurre il rischio di errore tipo M e aumentare la potenza."
  },
  {
    "objectID": "output.html#interpretazione-delloutput-8",
    "href": "output.html#interpretazione-delloutput-8",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nSono stati confrontati due modelli:\n\nBF1: mpg ~ wt\nBF2: mpg ~ wt + hp\n\nIl Bayes Factor (BF) confronta direttamente la probabilit√† dei dati sotto i due modelli.\nValore calcolato: BF2 / BF1\n\nSe BF &gt; 1 ‚Üí i dati supportano di pi√π il secondo modello.\nSe BF &lt; 1 ‚Üí i dati supportano di pi√π il primo modello.\n\nInterpretazione standard del BF:\n\n1‚Äì3: evidenza debole\n3‚Äì10: evidenza moderata\n(&gt;10): evidenza forte a favore del modello al numeratore\n\nIl BF √® una misura continua della forza di evidenza, a differenza del p-value che si basa su soglie arbitrarie."
  },
  {
    "objectID": "output.html#interpretazione-delloutput-9",
    "href": "output.html#interpretazione-delloutput-9",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üßæ Interpretazione dell‚ÄôOutput",
    "text": "üßæ Interpretazione dell‚ÄôOutput\n\nOgni cella della heatmap rappresenta il logaritmo del Bayes Factor tra due modelli specifici.\nIl colore indica la forza dell‚Äôevidenza:\n\nRosso: evidenza a favore del modello sulla riga rispetto a quello sulla colonna.\nBlu: evidenza a favore del modello sulla colonna rispetto a quello sulla riga.\nBianco: evidenza neutra o trascurabile.\n\nLa scala dei colori √® limitata tra -3 e 3 per facilitare l‚Äôinterpretazione visiva.\nQuesto tipo di visualizzazione consente un confronto diretto e intuitivo tra tutti i modelli considerati."
  },
  {
    "objectID": "output.html#tipologie-di-variabili",
    "href": "output.html#tipologie-di-variabili",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Tipologie di variabili",
    "text": "Tipologie di variabili\n\n\n\n\n\n\n\n\nTipo di variabile\nCaratteristiche\nEsempi\n\n\n\n\nEsogena\nNon √® spiegata da altre variabili nel modello\nEt√†, Sesso, Condizione sperimentale\n\n\nEndogena\n√à spiegata da almeno una variabile nel modello\nDepressione, Stress, Prestazione"
  },
  {
    "objectID": "output.html#dal-grafo-sem-come-riconoscerle",
    "href": "output.html#dal-grafo-sem-come-riconoscerle",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Dal grafo SEM: come riconoscerle?",
    "text": "Dal grafo SEM: come riconoscerle?\n\nFreccia in entrata (‚Üí) = variabile endogena\nSolo frecce in uscita = variabile esogena\nLe variabili latenti possono essere endogene o esogene a seconda del modello"
  },
  {
    "objectID": "output.html#modello-sem-ricorsivo-o-non-ricorsivo",
    "href": "output.html#modello-sem-ricorsivo-o-non-ricorsivo",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "Modello SEM ricorsivo o non ricorsivo",
    "text": "Modello SEM ricorsivo o non ricorsivo"
  },
  {
    "objectID": "output.html#definizioni",
    "href": "output.html#definizioni",
    "title": "üß≠ Schema decisionale (logico):",
    "section": "üß† Definizioni:",
    "text": "üß† Definizioni:\n\nRicorsivo:\n\nNessuna retroazione tra variabili endogene\nNessuna correlazione tra gli errori di variabili endogene\n\nNon ricorsivo:\n\nFeedback o relazioni bidirezionali\nErrori correlati tra variabili endogene"
  }
]